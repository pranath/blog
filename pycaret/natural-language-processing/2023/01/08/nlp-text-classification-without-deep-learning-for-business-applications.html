<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>NLP and Text Classification Without Deep Learning for Business Applications | livingdatalab</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="NLP and Text Classification Without Deep Learning for Business Applications" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Deep Learning and AI is powering some of the most recent amazing advances in text &amp; natural language processing (NLP) applications, such as GPT-3, Chat-GPT and Dall-E but these often require specialist resources such as deep learning. With Machine Learning (ML) its possible to create useful NLP applications for businesses without using AI and Deep Learning." />
<meta property="og:description" content="Deep Learning and AI is powering some of the most recent amazing advances in text &amp; natural language processing (NLP) applications, such as GPT-3, Chat-GPT and Dall-E but these often require specialist resources such as deep learning. With Machine Learning (ML) its possible to create useful NLP applications for businesses without using AI and Deep Learning." />
<link rel="canonical" href="https://www.livingdatalab.com/pycaret/natural-language-processing/2023/01/08/nlp-text-classification-without-deep-learning-for-business-applications.html" />
<meta property="og:url" content="https://www.livingdatalab.com/pycaret/natural-language-processing/2023/01/08/nlp-text-classification-without-deep-learning-for-business-applications.html" />
<meta property="og:site_name" content="livingdatalab" />
<meta property="og:image" content="https://www.livingdatalab.com/images/nlp-text-classification.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-01-08T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://www.livingdatalab.com/pycaret/natural-language-processing/2023/01/08/nlp-text-classification-without-deep-learning-for-business-applications.html","@type":"BlogPosting","headline":"NLP and Text Classification Without Deep Learning for Business Applications","dateModified":"2023-01-08T00:00:00-06:00","datePublished":"2023-01-08T00:00:00-06:00","image":"https://www.livingdatalab.com/images/nlp-text-classification.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.livingdatalab.com/pycaret/natural-language-processing/2023/01/08/nlp-text-classification-without-deep-learning-for-business-applications.html"},"description":"Deep Learning and AI is powering some of the most recent amazing advances in text &amp; natural language processing (NLP) applications, such as GPT-3, Chat-GPT and Dall-E but these often require specialist resources such as deep learning. With Machine Learning (ML) its possible to create useful NLP applications for businesses without using AI and Deep Learning.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://www.livingdatalab.com/feed.xml" title="livingdatalab" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-91568149-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">livingdatalab</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Livingdatalab</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">NLP and Text Classification Without Deep Learning for Business Applications</h1><p class="page-description">Deep Learning and AI is powering some of the most recent amazing advances in text & natural language processing (NLP) applications, such as GPT-3, Chat-GPT and Dall-E but these often require specialist resources such as deep learning. With Machine Learning (ML) its possible to create useful NLP applications for businesses without using AI and Deep Learning.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2023-01-08T00:00:00-06:00" itemprop="datePublished">
        Jan 8, 2023
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      29 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#pycaret">pycaret</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#natural-language-processing">natural-language-processing</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          
          
          
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Introduction">Introduction </a></li>
<li class="toc-entry toc-h2"><a href="#Business-Applications-of-NLP">Business Applications of NLP </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Market-Intelligence">Market Intelligence </a></li>
<li class="toc-entry toc-h3"><a href="#Sentiment-Analysis">Sentiment Analysis </a></li>
<li class="toc-entry toc-h3"><a href="#Text-Classification">Text Classification </a></li>
<li class="toc-entry toc-h3"><a href="#Topic-Modelling">Topic Modelling </a></li>
<li class="toc-entry toc-h3"><a href="#Recruiting-And-Hiring">Recruiting And Hiring </a></li>
<li class="toc-entry toc-h3"><a href="#Text-Summarization">Text Summarization </a></li>
<li class="toc-entry toc-h3"><a href="#Survey-Analysis">Survey Analysis </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Machine-Learning-vs-Deep-Learning-for-NLP-and-Business">Machine Learning vs Deep Learning for NLP and Business </a></li>
<li class="toc-entry toc-h2"><a href="#Pycaret-and-NLP">Pycaret and NLP </a></li>
<li class="toc-entry toc-h2"><a href="#Text-Classification-Without-Deep-Learning">Text Classification Without Deep Learning </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Topic-modelling---Discovering-hidden-categories-in-Kiva-loan-applications">Topic modelling - Discovering hidden categories in Kiva loan applications </a>
<ul>
<li class="toc-entry toc-h4"><a href="#What-are-topics-actually-about-?-Word-counts">What are topics actually about ? Word counts </a></li>
<li class="toc-entry toc-h4"><a href="#How-similar-or-different-are-topics?-Dimensionality-Reduction">How similar or different are topics? Dimensionality Reduction </a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#Sentiment-Analysis-&-Classification---Predict-if-Amazon-product-reviews-are-positive-or-negative">Sentiment Analysis &amp; Classification - Predict if Amazon product reviews are positive or negative </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Conclusion">Conclusion </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2023-01-08-nlp-text-classification-without-deep-learning-for-business-applications.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction">
<a class="anchor" href="#Introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction<a class="anchor-link" href="#Introduction"> </a>
</h2>
<p>Deep Learning and AI is powering some of the most recent amazing advances in text &amp; natural language processing (NLP) applications, such as GPT-3, Chat-GPT and Dall-E, but these often require specialist resources such as GPU servers that many businesses new to this technology don't have or can't yet justify these resources. With traditional Machine Learning (ML) its possible to create useful NLP applications such as text classification without using AI and Deep Learning, and in this article we will look at some examples of how these can provide useful business applications.</p>
<h2 id="Business-Applications-of-NLP">
<a class="anchor" href="#Business-Applications-of-NLP" aria-hidden="true"><span class="octicon octicon-link"></span></a>Business Applications of NLP<a class="anchor-link" href="#Business-Applications-of-NLP"> </a>
</h2>
<p>NLP (Natural Language Processing) is a branch of Artificial Intelligence (AI) and Data Science that is having a huge effect on all areas of society, including business.</p>
<p><strong>In essence, Natural language processing helps computers communicate with humans in their own language and scales other language-related tasks. For example, NLP makes it possible for computers to read text, hear speech, interpret it, measure sentiment and determine which parts are important.</strong></p>
<p>A recent article by the <a href="https://hbr.org/2022/04/the-power-of-natural-language-processing">Harvard Business Review</a> highlighted some of the huge potential NLP has for businesses.</p>
<blockquote>
<p>Until recently, the conventional wisdom was that while AI was better than humans at data-driven decision making tasks, it was still inferior to humans for cognitive and creative ones. But in the past two years language-based AI has advanced by leaps and bounds, changing common notions of what this technology can do. The most visible advances have been in what’s called “natural language processing” (NLP), the branch of AI focused on how computers can process language like humans do. It has been used to write an article for The Guardian, and AI-authored blog posts have gone viral — feats that weren’t possible a few years ago. AI even excels at cognitive tasks like programming where it is able to generate programs for simple video games from human instructions.</p>
</blockquote>
<p>A recent article on LinkedIn highlighted some of the <a href="https://www.linkedin.com/pulse/top-natural-language-processing-applications-business-mori-/?trk=pulse-article_more-articles_related-content-card">top business applications of NLP</a> these include:</p>
<h3 id="Market-Intelligence">
<a class="anchor" href="#Market-Intelligence" aria-hidden="true"><span class="octicon octicon-link"></span></a>Market Intelligence<a class="anchor-link" href="#Market-Intelligence"> </a>
</h3>
<p>Marketers can utilize natural language processing to understand their clients better and use those insights to develop more effective tactics. They can analyze subjects and keywords and make effective use of unstructured data thanks to the power of NLP. It can also determine your consumers pain points and maintain track of your competition.</p>
<h3 id="Sentiment-Analysis">
<a class="anchor" href="#Sentiment-Analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sentiment Analysis<a class="anchor-link" href="#Sentiment-Analysis"> </a>
</h3>
<p>Companies can regularly use sentiment analysis to acquire a better knowledge of their business. Humans can be sarcastic and sardonic during conversations. You may keep an eye on social media mentions and use real-time sentiment analysis to intervene before things get out of hand. Your company may sense the pulse of its customers with this NLP application. It also allows you to evaluate how your clients reacted to your most recent digital marketing campaign.</p>
<h3 id="Text-Classification">
<a class="anchor" href="#Text-Classification" aria-hidden="true"><span class="octicon octicon-link"></span></a>Text Classification<a class="anchor-link" href="#Text-Classification"> </a>
</h3>
<p>Text classification, is a text analysis task that also includes sentiment analysis, involves automatically understanding, processing, and categorizing unstructured text.</p>
<p>Let’s say you want to analyze hundreds of open-ended responses to your recent NPS survey. Doing it manually would take you a lot of time and end up being too expensive. But what if you could train a natural language processing model to automatically tag your data in just seconds, using predefined categories and applying your own criteria.</p>
<h3 id="Topic-Modelling">
<a class="anchor" href="#Topic-Modelling" aria-hidden="true"><span class="octicon octicon-link"></span></a>Topic Modelling<a class="anchor-link" href="#Topic-Modelling"> </a>
</h3>
<p>Topic modeling is an approach that can scan a series of documents, find word and phrase patterns within them, and automatically cluster word groupings and related expressions that best represent the set.</p>
<p>Topic Modeling doesn't require a preexisting list of tags or training data that has been previously categorized by humans, it can 'discover' what seem the most appropriate categories for a given set of documents for itself, based on which documents seem the most similar or different.</p>
<h3 id="Recruiting-And-Hiring">
<a class="anchor" href="#Recruiting-And-Hiring" aria-hidden="true"><span class="octicon octicon-link"></span></a>Recruiting And Hiring<a class="anchor-link" href="#Recruiting-And-Hiring"> </a>
</h3>
<p>We can all agree that picking the right staff is one of the most important duties performed by the HR department. However, HR has so much data in the current situation that sifting resumes and shortlisting prospects become overwhelming.</p>
<p>Natural Language Processing can help to make this work more accessible. HR experts can use information extraction and named entity recognition to extract information from candidates, such as their names, talents, locations, and educational histories. This enables unbiased resume filtering and the selection of the best candidate for the job.</p>
<h3 id="Text-Summarization">
<a class="anchor" href="#Text-Summarization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Text Summarization<a class="anchor-link" href="#Text-Summarization"> </a>
</h3>
<p>This NLP application extracts the most crucial information from a text and summarises it. The primary purpose is to speed up sifting through massive volumes of data in news articles, legal documents, and scientific studies. Text summarization can be done in two ways: extraction-based summarization, which selects crucial words and provides a summary without adding further information, and abstraction-based summarization, which paraphrases the original content to produce new terms.</p>
<h3 id="Survey-Analysis">
<a class="anchor" href="#Survey-Analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Survey Analysis<a class="anchor-link" href="#Survey-Analysis"> </a>
</h3>
<p>Surveys are an essential tool for businesses to use in evaluating their performance. Survey analysis is crucial in finding defects and supporting companies in improving their goods, whether gathering input on a new product launch or analyzing how effectively a company’s customer service is doing.
When many clients complete these surveys, the issue emerges, resulting in massive data. The human brain is unable to comprehend everything. At this time, natural language processing is introduced. These methods help organisations get accurate information about their consumers’ opinions and improve their performance.</p>
<h2 id="Machine-Learning-vs-Deep-Learning-for-NLP-and-Business">
<a class="anchor" href="#Machine-Learning-vs-Deep-Learning-for-NLP-and-Business" aria-hidden="true"><span class="octicon octicon-link"></span></a>Machine Learning vs Deep Learning for NLP and Business<a class="anchor-link" href="#Machine-Learning-vs-Deep-Learning-for-NLP-and-Business"> </a>
</h2>
<p>The most powerful and useful applications of NLP use <a href="https://www.ibm.com/topics/deep-learning">Deep Learning and AI</a> which is a sub-branch of Machine Learning. All the the most recent and most powerful applications of NLP such as GPT-3, Chat-GPT and Dall-E all use Deep Learning. Many would argue <a href="https://www.kdnuggets.com/2018/04/why-deep-learning-perfect-nlp-natural-language-processing.html">Deep Learning is perfect for NLP</a>.</p>
<p>In fact, <a href="https://livingdatalab.com/categories/#natural-language-processing">most of my own recent projects in NLP</a> over the last few years have almost exclusively used Deep Learning.</p>
<p>However before Deep Learning and AI existed and was developed recently, NLP still existed for many years and has its <a href="https://www.exxactcorp.com/blog/Deep-Learning/deep-learning-in-natural-language-processing-history-and-achievements">origins in work in the 1950's</a>. It just used different methods and techniques, that while not as powerful as Deep Learning and AI, still provided useful business applications and benefits at the time they were developed and used. These include the use of traddtional machine learning for NLP.</p>
<p>In a recent article i covered in more detail the differences between <a href="https://livingdatalab.com/fastai/fastai-2022/deep-learning/mathematics/2022/12/17/machine-learning-to-deep-learning-from-scratch.html">tradditonal machine learning and deep learning</a>.</p>
<p>Also, Deep Learning requires the use of specialist resources - namely <a href="https://towardsdatascience.com/what-is-a-gpu-and-do-you-need-one-in-deep-learning-718b9597aa0d">GPU servers</a>. Many businesses starting to explore the potental benefit of Data, Data Science, Machine Learning and AI don't always have the rescources or infrastructure setup to develop this technology.</p>
<p>Furthermore, some businesses may feel much more cautious to adopt this technology and the associated cost of resources, and may need a more gradual approach that takes them on a journey as much about education, learning what this technology can do to help solve business problems, as much as gradually using more and more advanced technology.</p>
<p>Some businesses, especially older &amp; established businesses with exisiting business practices, may need to learn slowly how to walk first before running with the most advanced technology!</p>
<p>With this in mind, it's good to know it is actually possible to develop useful and valuable NLP business applications - without the use of Deep Learning and the specialist resources that requires. While you might not get the best or near state of the art results for your solution, businesses can still gain huge value and benefit by using these slightly older methods compared to none at all.</p>
<h2 id="Pycaret-and-NLP">
<a class="anchor" href="#Pycaret-and-NLP" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pycaret and NLP<a class="anchor-link" href="#Pycaret-and-NLP"> </a>
</h2>
<p>NLP often requires a significant amount of code and steps to solve business problems. <a href="https://pycaret.org/">Pycaret</a> is a low code machine learning library, that allows you to perform common tasks in Data Science and Machine Learning with very little code, and has been listed in a recent article by Forbes as <a href="https://www.forbes.com/sites/bernardmarr/2022/12/12/the-10-best-examples-of-low-code-and-no-code-ai/?sh=29f5099274b5"><em>one of the 10 Best Examples Of Low-Code And No-Code AI</em></a></p>
<p>I've been using Pycaret myself professionally in my role as a Data Scientist as well as for <a href="https://livingdatalab.com/categories/#pycaret">personal projects</a> for over a year now and have found it incredibily useful to enable me to work much more quickly and efficiently. I've also written about how Pycaret is actually a <a href="https://livingdatalab.com/python-power-tools/pycaret/2021/12/04/python-power-tools-pycaret.html">Data Science Power Tool</a>.</p>
<p>In this project I will be using Pycaret for the NLP tasks we will be doing to solve certain business problems using machine learning.</p>
<h2 id="Text-Classification-Without-Deep-Learning">
<a class="anchor" href="#Text-Classification-Without-Deep-Learning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Text Classification Without Deep Learning<a class="anchor-link" href="#Text-Classification-Without-Deep-Learning"> </a>
</h2>
<p>Remembering our common uses of NLP, we are going to solve 2 different business problems to illustrate these methods:</p>
<ul>
<li>
<strong>Topic Modelling</strong>: We will use this method to try to discover what the hidden categories are for a dataset from <em>kiva - a crowdfunder for loans</em> which includes text data of each loan application. Or put another way - what kind of hidden topics would best describe peoples loan applications? For most busineses, it might be really useful to understand using customer text, such as customer contact form text etc, and discover what kind of topics customers were talking about without us knowing or assuming we know what they are before hand.</li>
<li>
<strong>Sentiment Analysis &amp; Classification</strong>: We will use this method to learn to predict the sentiment of <em>amazon customer product reviews</em> using the review text, and each of the positive or negative labels they have been assigned in the dataset. In other words, given a customer review text - to predict if this is a positive or negative review. This could be very useful for a business to understand if a product or service was succesful or not, by analysing thousands or even millions of customer reviews automatically and efficiently.</li>
</ul>
<p>Note, with Topic Modelling we are actually trying to discover new categories for a given set of texts, wheras with Sentiment Analysis &amp; Classification we are using an exisiting category. These are known as <em>unsupervised machine learning</em> and <em>supervised machine learning</em> respectively. In both cases, we produce something called a <em>model</em> which is something that we can then use on new text to predict what category that text is.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Topic-modelling---Discovering-hidden-categories-in-Kiva-loan-applications">
<a class="anchor" href="#Topic-modelling---Discovering-hidden-categories-in-Kiva-loan-applications" aria-hidden="true"><span class="octicon octicon-link"></span></a>Topic modelling - Discovering hidden categories in Kiva loan applications<a class="anchor-link" href="#Topic-modelling---Discovering-hidden-categories-in-Kiva-loan-applications"> </a>
</h3>
<p>Pycaret comes with some ready to use datasets such as Kiva. <a href="https://www.kiva.org/">Kiva</a> is a non-profit that allows individuals to lend money to low-income entrepreneurs and students around the world. The kiva dataset is data on individual loan applications which include the text of the application. Lets load and view the data.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">kiva</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">'kiva'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country</th>
      <th>en</th>
      <th>gender</th>
      <th>loan_amount</th>
      <th>nonpayment</th>
      <th>sector</th>
      <th>status</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Dominican Republic</td>
      <td>"Banco Esperanza" is a group of 10 women looking to receive a small loan. Each of them has taken out a very small loan already, so this would be their second. With this loan the group is going to try and expand their small businesses and start generating more income. &lt;P&gt;\n\nEduviges is the group representative and leader of the group. Eduviges has a lot on the line because she has 6 children that she has to take care of. She told me that those children are the reason she wants to be successful. She wants to be able to provide a different life for them and show them that they can be successful as well. &lt;P&gt;\n\nEduviges has a very small business selling shoes and Avon products. She plans to expand using this loan and dreams of success. The whole group is ready for this new challenge and a...</td>
      <td>F</td>
      <td>1225</td>
      <td>partner</td>
      <td>Retail</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Dominican Republic</td>
      <td>"Caminemos Hacia Adelante" or "Walking Forward" is a group of ten entrepreneurs seeking their second loan from Esperanza International. The groups past loan has been successfully repaid and the group hopes to use additional loan funds for further business expansion. \n\nEstella is one of the coordinators for this group in Santiago. Estella sells undergarments to her community and neighboring communities.  Estella used her first loan, which has now been completely repaid, to buy additional products and Estela was able to increase the return on her business by adding inventory.  Estella wants to use her second loan to buy more undergarments to sell to her customers.  \n\nEstella lives with her mother and sister and dreams of improving the house they live in and plans to use her business ...</td>
      <td>F</td>
      <td>1975</td>
      <td>lender</td>
      <td>Clothing</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Dominican Republic</td>
      <td>"Creciendo Por La Union" is a group of 10 people hoping to start their own businesses. This group is looking to receive loans to either start a small business or to try and increase their business. Everyone in this group is living in extreme poverty, and they see this as a chance to improve their lives and the lives of their families. \n\n"Dalina" is the group representative and was chosen because she is a very hardworking women. She is a young mother of two children, and she realized that she wanted a better life for her and her family. She is hoping to start a small business of selling clothes to people in her barrio. She hopes to someday have a thriving business and be able to provide for her family. On behalf of Dalina, the rest of the group, and Esperanza International: Thank you ...</td>
      <td>F</td>
      <td>2175</td>
      <td>partner</td>
      <td>Clothing</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Dominican Republic</td>
      <td>"Cristo Vive" ("Christ lives" is a group of 10 women who are looking to receive their first loans. This is a very young group of women, and they all want to start changing their lives right away. Riquena is the group representative and leader of this group, and she is only 18 years old. She is also married, but has no children. She told me that once she has kids she wants to be able to provide them with a good life, and that is the main reason she is trying to start her own business. She plans on selling used clothes in her area, and hopes to one day have a big clothing store, and also design clothes. She is a very motivated person, and you can see it when you speak with her. She speaks Spanish and Creole fluently, and is studying English. This whole group is ready for this next step, ...</td>
      <td>F</td>
      <td>1425</td>
      <td>partner</td>
      <td>Clothing</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Dominican Republic</td>
      <td>"Cristo Vive" is a large group of 35 people, 20 of which are hoping to take out a loan. For many of them this is their second loan, and a loan they hope to use to increase their business. The business range from clothing sales to salons. Miline is the chosen group representative due to her hard work and dedication. Miline is a hardworking mother of 5 very young children, the oldest being only 10 years old. She took her first loan and started a small business of selling chicken and other types of food. With this next loan she feels like she can increase her business greatly and start making money to support her family. Her dream is to have her own store someday, and be able to provide her family with comfortable life. On behalf of Miline, the group, and Esperanza International, thank yo...</td>
      <td>F</td>
      <td>4025</td>
      <td>partner</td>
      <td>Food</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's check how big the dataset is.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">kiva</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>6818</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we have around 7,000 loan applications. Lets now process and prepare the data.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">time</span> experiment1 = setup(data=kiva, target='en')
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<style type="text/css">
</style>
<table id="T_3bf27_">
  <thead>
    <tr>
      <th class="col_heading level0 col0">Description</th>
      <th class="col_heading level0 col1">Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td id="T_3bf27_row0_col0" class="data row0 col0">session_id</td>
      <td id="T_3bf27_row0_col1" class="data row0 col1">2214</td>
    </tr>
    <tr>
      <td id="T_3bf27_row1_col0" class="data row1 col0">Documents</td>
      <td id="T_3bf27_row1_col1" class="data row1 col1">6818</td>
    </tr>
    <tr>
      <td id="T_3bf27_row2_col0" class="data row2 col0">Vocab Size</td>
      <td id="T_3bf27_row2_col1" class="data row2 col1">12383</td>
    </tr>
    <tr>
      <td id="T_3bf27_row3_col0" class="data row3 col0">Custom Stopwords</td>
      <td id="T_3bf27_row3_col1" class="data row3 col1">False</td>
    </tr>
  </tbody>
</table>

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 1min 14s, sys: 295 ms, total: 1min 15s
Wall time: 1min 15s
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This single line of code has actually performed a large number of tasks that would normally take many lines of code, but in Pycaret is a single line of code. You can find out more about what this line does for NLP text pre-processing <a href="https://www.pycaret.org/tutorials/html/NLP101.html">here</a>.</p>
<p>Now our data is prepared, lets create our topic model.</p>
<p>For topic modelling we will be using the <a href="https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24">Latent Dirichlet Allocation (LDA)</a> technique. I've written previously about the mathemetics behind two other techniques called <a href="https://livingdatalab.com/mathematics/linear-algebra/natural-language-processing/2021/12/28/topic-modelling-nmf.html">Non-negative Matrix Factorization (NMF)</a> and <a href="https://livingdatalab.com/mathematics/linear-algebra/natural-language-processing/2021/12/27/topic-modelling-svd.html">Singular Value Decomposition (SVD)</a>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lda_topic_model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">'lda'</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we now have our topic model. Notice we have set 'num_topics=4' - this means the model tries to discover the 4 topics that seem most relevant to the loan applications. We could set this to a different number if we wanted to.</p>
<p>Now we have discovered our 4 topics for the loan applications and trained a model to recognise them, we can use this model to predict each of these 4 topics for all our applications using the <em>assign_model()</em> function.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lda_results</span> <span class="o">=</span> <span class="n">assign_model</span><span class="p">(</span><span class="n">lda_topic_model</span><span class="p">)</span>
<span class="n">lda_results</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country</th>
      <th>en</th>
      <th>gender</th>
      <th>loan_amount</th>
      <th>nonpayment</th>
      <th>sector</th>
      <th>status</th>
      <th>Topic_0</th>
      <th>Topic_1</th>
      <th>Topic_2</th>
      <th>Topic_3</th>
      <th>Dominant_Topic</th>
      <th>Perc_Dominant_Topic</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Dominican Republic</td>
      <td>group woman look receive small loan take small loan already second loan group go try expand small business start generate income group representative leader group eduvige lot line child tell child reason want successful want able provide different life show successful well eduvige small business selling shoe avon product plan expand use loan dream success whole group ready new challenge road better live behalf eduvige thank support</td>
      <td>F</td>
      <td>1225</td>
      <td>partner</td>
      <td>Retail</td>
      <td>0</td>
      <td>0.410590</td>
      <td>0.044232</td>
      <td>0.001707</td>
      <td>0.543472</td>
      <td>Topic 3</td>
      <td>0.54</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Dominican Republic</td>
      <td>caminemos walk forward group entrepreneur seek second loan esperanza_international group loan successfully_repaid group hope use additional loan fund business expansion coordinator group sell undergarment community neighboring community use first loan completely repay buy additional product estela able increase return business add inventory estella want use second loan buy undergarment sell customer live mother sister dream improve house live plan use business profit member art juice ice_cream fry food cake sale behalf esperanza group business entrepreneur like thank support</td>
      <td>F</td>
      <td>1975</td>
      <td>lender</td>
      <td>Clothing</td>
      <td>0</td>
      <td>0.608610</td>
      <td>0.084845</td>
      <td>0.001478</td>
      <td>0.305067</td>
      <td>Topic 0</td>
      <td>0.61</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Dominican Republic</td>
      <td>por la_union group people hope start business group look receive loan start small business try increase business group poverty see chance improve life live family representative choose hardworke woman young mother child realize want well life family hope start small business sell clothe people barrio hope someday thrive business able provide family behalf thank support</td>
      <td>F</td>
      <td>2175</td>
      <td>partner</td>
      <td>Clothing</td>
      <td>0</td>
      <td>0.486984</td>
      <td>0.012169</td>
      <td>0.002022</td>
      <td>0.498825</td>
      <td>Topic 3</td>
      <td>0.50</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Dominican Republic</td>
      <td>vive live group woman look receive first loan young group woman want start change life right away riquena group representative leader group year old also marry child tell kid want able provide good life main reason try start business plan sell use clothe area hope day big clothing store also design clothe motivated person see speak speak spanish creole fluently study english whole group ready next step excited_opportunity behalf thank support</td>
      <td>F</td>
      <td>1425</td>
      <td>partner</td>
      <td>Clothing</td>
      <td>0</td>
      <td>0.289351</td>
      <td>0.071750</td>
      <td>0.001620</td>
      <td>0.637279</td>
      <td>Topic 3</td>
      <td>0.64</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Dominican Republic</td>
      <td>cristo vive large group people hope take loan many second loan hope use increase business business range clothing sale salon miline choose group representative due hard work dedication miline hardworke mother young child old year old take first loan start small business sell chicken type food next loan feel increase business greatly start make money support family dream store someday able provide family comfortable life behalf miline thank support</td>
      <td>F</td>
      <td>4025</td>
      <td>partner</td>
      <td>Food</td>
      <td>0</td>
      <td>0.562529</td>
      <td>0.032050</td>
      <td>0.001672</td>
      <td>0.403749</td>
      <td>Topic 0</td>
      <td>0.56</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see the topic model has given us several new things. Firstly, for each loan application it has given us a measure of how much of each of the 4 topics that loan application scores for - which would be a value between 0 and 1. Secondly, for each loan application <em>Dominant_Topic</em> tells us which is the most important topic. Finally, <em>Perc_Dominant_Topic</em> tells hows how highly that loan application scores for its dominant topic.</p>
<p>Lets have a look at how many loan applications are within each of the 4 topics, Pycaret makes this very easy using the <em>plot_model()</em> function.</p>
<p><strong>plot_model(lda_topic_model, plot = 'topic_distribution')</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://github.com/pranath/blog/raw/master/images/topic1.png" alt="" title="Topic Distribution"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we can see that topic 0 covers most of the loan applications, and the other topics much less, with topic 1 having very few examples.</p>
<h4 id="What-are-topics-actually-about-?-Word-counts">
<a class="anchor" href="#What-are-topics-actually-about-?-Word-counts" aria-hidden="true"><span class="octicon octicon-link"></span></a>What are topics actually about ? Word counts<a class="anchor-link" href="#What-are-topics-actually-about-?-Word-counts"> </a>
</h4>
<p>How can we find out what these hidden topics are about? We can look at the top 100 words in the text of each topic to give us some idea.</p>
<p>Again, Pycaret makes this very easy again using the <em>plot_model()</em> function.</p>
<p><strong>plot_model(lda_topic_model, plot = 'frequency', topic_num = 'Topic 0')</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://github.com/pranath/blog/raw/master/images/topic2.png" alt="" title="Topic 0"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we can see for topic 0 the top 4 words are:</p>
<ul>
<li>Business</li>
<li>Year</li>
<li>Child</li>
<li>Old</li>
</ul>
<p>You could imagine perhaps the loan applications for this topic might emphasise for example how these loans would have a benefit in a specific year, or would benefit perhaps both older and younger people in the community?</p>
<p>Lets have a look at topic 1.</p>
<p><strong>plot_model(lda_topic_model, plot = 'frequency', topic_num = 'Topic 1')</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://github.com/pranath/blog/raw/master/images/topic3.png" alt="" title="Topic 1"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we can see for topic 1 the top 4 words are:</p>
<ul>
<li>Year</li>
<li>Loan</li>
<li>Community</li>
<li>Clinic</li>
</ul>
<p>Perhaps applications under this topic tend to emphasise how the loan might benefit the local community, including healthcare services specifically?</p>
<p>Lets examine topic 2.</p>
<p><strong>plot_model(lda_topic_model, plot = 'frequency', topic_num = 'Topic 2')</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://github.com/pranath/blog/raw/master/images/topic4.png" alt="" title="Topic 2"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we can see for topic 2 the top 4 words are:</p>
<ul>
<li>Rice</li>
<li>Farmer</li>
<li>Use</li>
<li>Sector</li>
</ul>
<p>For this topic it might be the case that these loan applications could be for projects more relating to agriculture and food production.</p>
<p>Finally lets explore topic 3.</p>
<p><strong>plot_model(lda_topic_model, plot = 'frequency', topic_num = 'Topic 3')</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://github.com/pranath/blog/raw/master/images/topic5.png" alt="" title="Topic 3"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The top 4 words for topic 3 are:</p>
<ul>
<li>Loan</li>
<li>Child</li>
<li>School</li>
<li>Sell</li>
</ul>
<p>You could imagine that perhaps loans under this topic might be related to education and schools, and perhaps also the buying and selling of products for schools or children.</p>
<p>So this have given us some good indications as to what the different hidden topics might be about regarding these loan applications.</p>
<h4 id="How-similar-or-different-are-topics?-Dimensionality-Reduction">
<a class="anchor" href="#How-similar-or-different-are-topics?-Dimensionality-Reduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>How similar or different are topics? Dimensionality Reduction<a class="anchor-link" href="#How-similar-or-different-are-topics?-Dimensionality-Reduction"> </a>
</h4>
<p>Another thing we can do is look at these loan applicaton texts spatially. We can convert these texts into numbers that represent these texts in terms of their meaning, then plot these numbers as points in 3D space. Each point will then represent an individual loan application, and points that are closer will be applications that are more similar, and points further away applications more different.</p>
<p>This general approach of reducing data down into simplified numbers is called <em>Dimenstionality Reduction</em> and you can find more about these methods in an <a href="https://github.com/pranath/high_dim_data_vis">earlier project i did on this</a>. We will use a method for this called TSNE.</p>
<p>Again Pycaret makes this very easy to do using the <em>plot_model()</em> function.</p>
<p><strong>plot_model(lda_topic_model, plot = 'tsne')</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://github.com/pranath/blog/raw/master/images/topic6.png" alt="" title="TSNE Plot"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can tell a few things from this view of the loan applications and topics:</p>
<ul>
<li>All topics seem to be fairly distinct with little overlap</li>
<li>Topic 0, 1 &amp; 3 seem to meet at the edges suggesting there are a few cases that could be in either topic</li>
<li>Topic 2 seems to be the most unique, its the most separated from the others spatially</li>
</ul>
<p>This seems to confirm what we found when we looked at the top words from each topic, topic 2 was about farming and agriculture which really was much more unique compared to the other topics, which had a little more overlap between them.</p>
<p>So we can see that topic modelling can be a very useful technique for businesses to provide insight on a group of text that we may know nothing about. It can help us discover hidden categories among these texts, how many are under each of these categories, how closely related or distinct these categories are - and much more. This could easily be applied to customer queries, survey responses, transcripts of customer conversations or emails, and more - to help businesses gain useful insights from their textual data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Sentiment-Analysis-&amp;-Classification---Predict-if-Amazon-product-reviews-are-positive-or-negative">
<a class="anchor" href="#Sentiment-Analysis-&amp;-Classification---Predict-if-Amazon-product-reviews-are-positive-or-negative" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sentiment Analysis &amp; Classification - Predict if Amazon product reviews are positive or negative<a class="anchor-link" href="#Sentiment-Analysis-&amp;-Classification---Predict-if-Amazon-product-reviews-are-positive-or-negative"> </a>
</h3>
<p>Pycaret also comes with a dataset of amazon product reviews, lets load these and have a look.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">amazon_reviews</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">'amazon'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>reviewText</th>
      <th>Positive</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>This is a one of the best apps acording to a bunch of people and I agree it has bombs eggs pigs TNT king pigs and realustic stuff</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>This is a pretty good version of the game for being free. There are LOTS of different levels to play. My kids enjoy it a lot too.</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>this is a really cool game. there are a bunch of levels and you can find golden eggs. super fun.</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>This is a silly game and can be frustrating, but lots of fun and definitely recommend just as a fun time.</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>This is a terrific game on any pad. Hrs of fun.  My grandkids love it. Great entertainment when waiting in long lines</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we can see we have just a column for the text of the review, and another called 'Positive' which is a label to indicate if the review was positive or not i.e. 1 or 0. Let's see how many reviews we have.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">amazon_reviews</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we have around 20,000 reviews. Lets get a count of how many positive and negative reviews we have.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">amazon_reviews</span><span class="p">[</span><span class="s1">'Positive'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1    15233
0     4767
Name: Positive, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So around 75% of the reviews are positive, and 25% negative reviews.</p>
<p>To create a classification model, we will first need to create some <em>features</em>. These are essentially numbers that represent something we are trying to predict, so given we are trying to predict if a review is positive or negative, these features need to represent something about the text that will help us predict that.</p>
<p>There are many methods of turning text into numeric features, but we are actually going to use <em>topic modelling</em> to create some topics to describe our text, and use these as features to help our classfier model to predict positive or negative sentiment.</p>
<p>Lets set up and process our review data for topic modelling.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">time</span> experiment2 = setup(data=amazon_reviews, target='reviewText')
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<style type="text/css">
</style>
<table id="T_0c790_">
  <thead>
    <tr>
      <th class="col_heading level0 col0">Description</th>
      <th class="col_heading level0 col1">Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td id="T_0c790_row0_col0" class="data row0 col0">session_id</td>
      <td id="T_0c790_row0_col1" class="data row0 col1">497</td>
    </tr>
    <tr>
      <td id="T_0c790_row1_col0" class="data row1 col0">Documents</td>
      <td id="T_0c790_row1_col1" class="data row1 col1">20000</td>
    </tr>
    <tr>
      <td id="T_0c790_row2_col0" class="data row2 col0">Vocab Size</td>
      <td id="T_0c790_row2_col1" class="data row2 col1">12771</td>
    </tr>
    <tr>
      <td id="T_0c790_row3_col0" class="data row3 col0">Custom Stopwords</td>
      <td id="T_0c790_row3_col1" class="data row3 col1">False</td>
    </tr>
  </tbody>
</table>

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 1min 28s, sys: 1.51 s, total: 1min 30s
Wall time: 1min 35s
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As before we will create a topic model to create some new categories.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lda_topic_model2</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">'lda'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's now predict these categories for our reviews.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lda_results</span> <span class="o">=</span> <span class="n">assign_model</span><span class="p">(</span><span class="n">lda_topic_model2</span><span class="p">)</span>
<span class="n">lda_results</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>reviewText</th>
      <th>Positive</th>
      <th>Topic_0</th>
      <th>Topic_1</th>
      <th>Topic_2</th>
      <th>Topic_3</th>
      <th>Dominant_Topic</th>
      <th>Perc_Dominant_Topic</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>good app acorde bunch people agree bomb egg pig king pig realustic stuff</td>
      <td>1</td>
      <td>0.081603</td>
      <td>0.309925</td>
      <td>0.227132</td>
      <td>0.381340</td>
      <td>Topic 3</td>
      <td>0.38</td>
    </tr>
    <tr>
      <th>1</th>
      <td>pretty good version game free lot different level play kid enjoy lot</td>
      <td>1</td>
      <td>0.070119</td>
      <td>0.200039</td>
      <td>0.249249</td>
      <td>0.480594</td>
      <td>Topic 3</td>
      <td>0.48</td>
    </tr>
    <tr>
      <th>2</th>
      <td>really cool game bunch level find golden egg super fun</td>
      <td>1</td>
      <td>0.116654</td>
      <td>0.263965</td>
      <td>0.197222</td>
      <td>0.422159</td>
      <td>Topic 3</td>
      <td>0.42</td>
    </tr>
    <tr>
      <th>3</th>
      <td>silly game frustrating lot fun definitely recommend fun time</td>
      <td>1</td>
      <td>0.077698</td>
      <td>0.148072</td>
      <td>0.309584</td>
      <td>0.464646</td>
      <td>Topic 3</td>
      <td>0.46</td>
    </tr>
    <tr>
      <th>4</th>
      <td>terrific game pad fun grandkid love great entertainment wait long line</td>
      <td>1</td>
      <td>0.072539</td>
      <td>0.138212</td>
      <td>0.424701</td>
      <td>0.364547</td>
      <td>Topic 2</td>
      <td>0.42</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So our data is almost ready. Our classification model does'nt need the text data now as we have represented the text using values for our new categories created by our topic model. We also don't need the Dominant or Perc topic fields, so lets drop these columns.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lda_results</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">'reviewText'</span><span class="p">,</span> <span class="s1">'Dominant_Topic'</span><span class="p">,</span> <span class="s1">'Perc_Dominant_Topic'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">lda_results</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Positive</th>
      <th>Topic_0</th>
      <th>Topic_1</th>
      <th>Topic_2</th>
      <th>Topic_3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0.081603</td>
      <td>0.309925</td>
      <td>0.227132</td>
      <td>0.381340</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0.070119</td>
      <td>0.200039</td>
      <td>0.249249</td>
      <td>0.480594</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>0.116654</td>
      <td>0.263965</td>
      <td>0.197222</td>
      <td>0.422159</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>0.077698</td>
      <td>0.148072</td>
      <td>0.309584</td>
      <td>0.464646</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>0.072539</td>
      <td>0.138212</td>
      <td>0.424701</td>
      <td>0.364547</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It's common practice when training classification models to split the data, some to train the model on, and some to test the model later. Let's split this data of 20,000 reviews, to give is a small test data set.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">split_data</span><span class="p">(</span><span class="n">lda_results</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's now set the data up, this time to prepare it for classification model training using our training data.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">time</span> experiment3 = setup(data=train, target='Positive')
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<style type="text/css">
#T_e05ea_row7_col1 {
  background-color: lightgreen;
}
</style>
<table id="T_e05ea_">
  <thead>
    <tr>
      <th class="blank level0"> </th>
      <th class="col_heading level0 col0">Description</th>
      <th class="col_heading level0 col1">Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_e05ea_level0_row0" class="row_heading level0 row0">0</th>
      <td id="T_e05ea_row0_col0" class="data row0 col0">Session id</td>
      <td id="T_e05ea_row0_col1" class="data row0 col1">227</td>
    </tr>
    <tr>
      <th id="T_e05ea_level0_row1" class="row_heading level0 row1">1</th>
      <td id="T_e05ea_row1_col0" class="data row1 col0">Target</td>
      <td id="T_e05ea_row1_col1" class="data row1 col1">Positive</td>
    </tr>
    <tr>
      <th id="T_e05ea_level0_row2" class="row_heading level0 row2">2</th>
      <td id="T_e05ea_row2_col0" class="data row2 col0">Target type</td>
      <td id="T_e05ea_row2_col1" class="data row2 col1">classification</td>
    </tr>
    <tr>
      <th id="T_e05ea_level0_row3" class="row_heading level0 row3">3</th>
      <td id="T_e05ea_row3_col0" class="data row3 col0">Data shape</td>
      <td id="T_e05ea_row3_col1" class="data row3 col1">(19980, 5)</td>
    </tr>
    <tr>
      <th id="T_e05ea_level0_row4" class="row_heading level0 row4">4</th>
      <td id="T_e05ea_row4_col0" class="data row4 col0">Train data shape</td>
      <td id="T_e05ea_row4_col1" class="data row4 col1">(13985, 5)</td>
    </tr>
    <tr>
      <th id="T_e05ea_level0_row5" class="row_heading level0 row5">5</th>
      <td id="T_e05ea_row5_col0" class="data row5 col0">Test data shape</td>
      <td id="T_e05ea_row5_col1" class="data row5 col1">(5995, 5)</td>
    </tr>
    <tr>
      <th id="T_e05ea_level0_row6" class="row_heading level0 row6">6</th>
      <td id="T_e05ea_row6_col0" class="data row6 col0">Numeric features</td>
      <td id="T_e05ea_row6_col1" class="data row6 col1">4</td>
    </tr>
    <tr>
      <th id="T_e05ea_level0_row7" class="row_heading level0 row7">7</th>
      <td id="T_e05ea_row7_col0" class="data row7 col0">Preprocess</td>
      <td id="T_e05ea_row7_col1" class="data row7 col1">True</td>
    </tr>
    <tr>
      <th id="T_e05ea_level0_row8" class="row_heading level0 row8">8</th>
      <td id="T_e05ea_row8_col0" class="data row8 col0">Imputation type</td>
      <td id="T_e05ea_row8_col1" class="data row8 col1">simple</td>
    </tr>
    <tr>
      <th id="T_e05ea_level0_row9" class="row_heading level0 row9">9</th>
      <td id="T_e05ea_row9_col0" class="data row9 col0">Numeric imputation</td>
      <td id="T_e05ea_row9_col1" class="data row9 col1">mean</td>
    </tr>
    <tr>
      <th id="T_e05ea_level0_row10" class="row_heading level0 row10">10</th>
      <td id="T_e05ea_row10_col0" class="data row10 col0">Categorical imputation</td>
      <td id="T_e05ea_row10_col1" class="data row10 col1">constant</td>
    </tr>
    <tr>
      <th id="T_e05ea_level0_row11" class="row_heading level0 row11">11</th>
      <td id="T_e05ea_row11_col0" class="data row11 col0">Fold Generator</td>
      <td id="T_e05ea_row11_col1" class="data row11 col1">StratifiedKFold</td>
    </tr>
    <tr>
      <th id="T_e05ea_level0_row12" class="row_heading level0 row12">12</th>
      <td id="T_e05ea_row12_col0" class="data row12 col0">Fold Number</td>
      <td id="T_e05ea_row12_col1" class="data row12 col1">10</td>
    </tr>
    <tr>
      <th id="T_e05ea_level0_row13" class="row_heading level0 row13">13</th>
      <td id="T_e05ea_row13_col0" class="data row13 col0">CPU Jobs</td>
      <td id="T_e05ea_row13_col1" class="data row13 col1">-1</td>
    </tr>
    <tr>
      <th id="T_e05ea_level0_row14" class="row_heading level0 row14">14</th>
      <td id="T_e05ea_row14_col0" class="data row14 col0">Log Experiment</td>
      <td id="T_e05ea_row14_col1" class="data row14 col1">False</td>
    </tr>
    <tr>
      <th id="T_e05ea_level0_row15" class="row_heading level0 row15">15</th>
      <td id="T_e05ea_row15_col0" class="data row15 col0">Experiment Name</td>
      <td id="T_e05ea_row15_col1" class="data row15 col1">clf-default-name</td>
    </tr>
    <tr>
      <th id="T_e05ea_level0_row16" class="row_heading level0 row16">16</th>
      <td id="T_e05ea_row16_col0" class="data row16 col0">USI</td>
      <td id="T_e05ea_row16_col1" class="data row16 col1">22b0</td>
    </tr>
  </tbody>
</table>

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 259 ms, sys: 8.99 ms, total: 267 ms
Wall time: 269 ms
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's now train a range of different models to predict the positive or negative sentiment, and choose the best one.</p>
<p>Again Pycaret makes this very easy to do something that would normally take many lines of code to do.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">compare_models</span><span class="p">(</span><span class="n">exclude</span><span class="o">=</span><span class="s1">'dummy'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<style type="text/css">
#T_62f96_ th {
  text-align: left;
}
#T_62f96_row0_col0, #T_62f96_row0_col2, #T_62f96_row0_col4, #T_62f96_row0_col6, #T_62f96_row0_col7, #T_62f96_row1_col0, #T_62f96_row1_col1, #T_62f96_row1_col2, #T_62f96_row1_col3, #T_62f96_row1_col4, #T_62f96_row1_col5, #T_62f96_row1_col6, #T_62f96_row1_col7, #T_62f96_row2_col0, #T_62f96_row2_col1, #T_62f96_row2_col2, #T_62f96_row2_col3, #T_62f96_row2_col4, #T_62f96_row2_col5, #T_62f96_row2_col6, #T_62f96_row2_col7, #T_62f96_row3_col0, #T_62f96_row3_col1, #T_62f96_row3_col2, #T_62f96_row3_col3, #T_62f96_row3_col4, #T_62f96_row3_col5, #T_62f96_row3_col6, #T_62f96_row3_col7, #T_62f96_row4_col0, #T_62f96_row4_col1, #T_62f96_row4_col3, #T_62f96_row4_col4, #T_62f96_row4_col5, #T_62f96_row4_col6, #T_62f96_row4_col7, #T_62f96_row5_col0, #T_62f96_row5_col1, #T_62f96_row5_col2, #T_62f96_row5_col3, #T_62f96_row5_col4, #T_62f96_row5_col5, #T_62f96_row5_col6, #T_62f96_row5_col7, #T_62f96_row6_col0, #T_62f96_row6_col1, #T_62f96_row6_col2, #T_62f96_row6_col3, #T_62f96_row6_col4, #T_62f96_row6_col5, #T_62f96_row6_col6, #T_62f96_row6_col7, #T_62f96_row7_col0, #T_62f96_row7_col1, #T_62f96_row7_col2, #T_62f96_row7_col3, #T_62f96_row7_col4, #T_62f96_row7_col5, #T_62f96_row7_col6, #T_62f96_row7_col7, #T_62f96_row8_col0, #T_62f96_row8_col1, #T_62f96_row8_col2, #T_62f96_row8_col3, #T_62f96_row8_col4, #T_62f96_row8_col5, #T_62f96_row8_col6, #T_62f96_row9_col0, #T_62f96_row9_col1, #T_62f96_row9_col2, #T_62f96_row9_col3, #T_62f96_row9_col4, #T_62f96_row9_col5, #T_62f96_row9_col6, #T_62f96_row9_col7, #T_62f96_row10_col0, #T_62f96_row10_col1, #T_62f96_row10_col2, #T_62f96_row10_col3, #T_62f96_row10_col4, #T_62f96_row10_col5, #T_62f96_row10_col6, #T_62f96_row10_col7, #T_62f96_row11_col0, #T_62f96_row11_col1, #T_62f96_row11_col2, #T_62f96_row11_col3, #T_62f96_row11_col4, #T_62f96_row11_col5, #T_62f96_row11_col7, #T_62f96_row12_col0, #T_62f96_row12_col1, #T_62f96_row12_col2, #T_62f96_row12_col3, #T_62f96_row12_col4, #T_62f96_row12_col5, #T_62f96_row12_col6, #T_62f96_row12_col7, #T_62f96_row13_col0, #T_62f96_row13_col1, #T_62f96_row13_col2, #T_62f96_row13_col3, #T_62f96_row13_col4, #T_62f96_row13_col5, #T_62f96_row13_col6, #T_62f96_row13_col7, #T_62f96_row14_col0, #T_62f96_row14_col1, #T_62f96_row14_col2, #T_62f96_row14_col3, #T_62f96_row14_col5, #T_62f96_row14_col6, #T_62f96_row14_col7 {
  text-align: left;
}
#T_62f96_row0_col1, #T_62f96_row0_col3, #T_62f96_row0_col5, #T_62f96_row4_col2, #T_62f96_row8_col7, #T_62f96_row11_col6, #T_62f96_row14_col4 {
  text-align: left;
  background-color: yellow;
}
#T_62f96_row0_col8, #T_62f96_row1_col8, #T_62f96_row3_col8, #T_62f96_row4_col8, #T_62f96_row5_col8, #T_62f96_row6_col8, #T_62f96_row7_col8, #T_62f96_row8_col8, #T_62f96_row9_col8, #T_62f96_row10_col8, #T_62f96_row11_col8, #T_62f96_row12_col8, #T_62f96_row13_col8, #T_62f96_row14_col8 {
  text-align: left;
  background-color: lightgrey;
}
#T_62f96_row2_col8 {
  text-align: left;
  background-color: yellow;
  background-color: lightgrey;
}
</style>
<table id="T_62f96_">
  <thead>
    <tr>
      <th class="blank level0"> </th>
      <th class="col_heading level0 col0">Model</th>
      <th class="col_heading level0 col1">Accuracy</th>
      <th class="col_heading level0 col2">AUC</th>
      <th class="col_heading level0 col3">Recall</th>
      <th class="col_heading level0 col4">Prec.</th>
      <th class="col_heading level0 col5">F1</th>
      <th class="col_heading level0 col6">Kappa</th>
      <th class="col_heading level0 col7">MCC</th>
      <th class="col_heading level0 col8">TT (Sec)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_62f96_level0_row0" class="row_heading level0 row0">svm</th>
      <td id="T_62f96_row0_col0" class="data row0 col0">SVM - Linear Kernel</td>
      <td id="T_62f96_row0_col1" class="data row0 col1">0.7618</td>
      <td id="T_62f96_row0_col2" class="data row0 col2">0.0000</td>
      <td id="T_62f96_row0_col3" class="data row0 col3">1.0000</td>
      <td id="T_62f96_row0_col4" class="data row0 col4">0.7618</td>
      <td id="T_62f96_row0_col5" class="data row0 col5">0.8648</td>
      <td id="T_62f96_row0_col6" class="data row0 col6">0.0000</td>
      <td id="T_62f96_row0_col7" class="data row0 col7">0.0000</td>
      <td id="T_62f96_row0_col8" class="data row0 col8">0.0220</td>
    </tr>
    <tr>
      <th id="T_62f96_level0_row1" class="row_heading level0 row1">lr</th>
      <td id="T_62f96_row1_col0" class="data row1 col0">Logistic Regression</td>
      <td id="T_62f96_row1_col1" class="data row1 col1">0.7617</td>
      <td id="T_62f96_row1_col2" class="data row1 col2">0.6472</td>
      <td id="T_62f96_row1_col3" class="data row1 col3">0.9981</td>
      <td id="T_62f96_row1_col4" class="data row1 col4">0.7625</td>
      <td id="T_62f96_row1_col5" class="data row1 col5">0.8645</td>
      <td id="T_62f96_row1_col6" class="data row1 col6">0.0053</td>
      <td id="T_62f96_row1_col7" class="data row1 col7">0.0294</td>
      <td id="T_62f96_row1_col8" class="data row1 col8">0.0290</td>
    </tr>
    <tr>
      <th id="T_62f96_level0_row2" class="row_heading level0 row2">ridge</th>
      <td id="T_62f96_row2_col0" class="data row2 col0">Ridge Classifier</td>
      <td id="T_62f96_row2_col1" class="data row2 col1">0.7617</td>
      <td id="T_62f96_row2_col2" class="data row2 col2">0.0000</td>
      <td id="T_62f96_row2_col3" class="data row2 col3">0.9992</td>
      <td id="T_62f96_row2_col4" class="data row2 col4">0.7620</td>
      <td id="T_62f96_row2_col5" class="data row2 col5">0.8646</td>
      <td id="T_62f96_row2_col6" class="data row2 col6">0.0019</td>
      <td id="T_62f96_row2_col7" class="data row2 col7">0.0150</td>
      <td id="T_62f96_row2_col8" class="data row2 col8">0.0160</td>
    </tr>
    <tr>
      <th id="T_62f96_level0_row3" class="row_heading level0 row3">lda</th>
      <td id="T_62f96_row3_col0" class="data row3 col0">Linear Discriminant Analysis</td>
      <td id="T_62f96_row3_col1" class="data row3 col1">0.7616</td>
      <td id="T_62f96_row3_col2" class="data row3 col2">0.6474</td>
      <td id="T_62f96_row3_col3" class="data row3 col3">0.9948</td>
      <td id="T_62f96_row3_col4" class="data row3 col4">0.7637</td>
      <td id="T_62f96_row3_col5" class="data row3 col5">0.8641</td>
      <td id="T_62f96_row3_col6" class="data row3 col6">0.0156</td>
      <td id="T_62f96_row3_col7" class="data row3 col7">0.0512</td>
      <td id="T_62f96_row3_col8" class="data row3 col8">0.0210</td>
    </tr>
    <tr>
      <th id="T_62f96_level0_row4" class="row_heading level0 row4">gbc</th>
      <td id="T_62f96_row4_col0" class="data row4 col0">Gradient Boosting Classifier</td>
      <td id="T_62f96_row4_col1" class="data row4 col1">0.7610</td>
      <td id="T_62f96_row4_col2" class="data row4 col2">0.6559</td>
      <td id="T_62f96_row4_col3" class="data row4 col3">0.9965</td>
      <td id="T_62f96_row4_col4" class="data row4 col4">0.7626</td>
      <td id="T_62f96_row4_col5" class="data row4 col5">0.8640</td>
      <td id="T_62f96_row4_col6" class="data row4 col6">0.0065</td>
      <td id="T_62f96_row4_col7" class="data row4 col7">0.0282</td>
      <td id="T_62f96_row4_col8" class="data row4 col8">0.8190</td>
    </tr>
    <tr>
      <th id="T_62f96_level0_row5" class="row_heading level0 row5">ada</th>
      <td id="T_62f96_row5_col0" class="data row5 col0">Ada Boost Classifier</td>
      <td id="T_62f96_row5_col1" class="data row5 col1">0.7602</td>
      <td id="T_62f96_row5_col2" class="data row5 col2">0.6476</td>
      <td id="T_62f96_row5_col3" class="data row5 col3">0.9937</td>
      <td id="T_62f96_row5_col4" class="data row5 col4">0.7631</td>
      <td id="T_62f96_row5_col5" class="data row5 col5">0.8633</td>
      <td id="T_62f96_row5_col6" class="data row5 col6">0.0103</td>
      <td id="T_62f96_row5_col7" class="data row5 col7">0.0318</td>
      <td id="T_62f96_row5_col8" class="data row5 col8">0.2600</td>
    </tr>
    <tr>
      <th id="T_62f96_level0_row6" class="row_heading level0 row6">catboost</th>
      <td id="T_62f96_row6_col0" class="data row6 col0">CatBoost Classifier</td>
      <td id="T_62f96_row6_col1" class="data row6 col1">0.7600</td>
      <td id="T_62f96_row6_col2" class="data row6 col2">0.6468</td>
      <td id="T_62f96_row6_col3" class="data row6 col3">0.9868</td>
      <td id="T_62f96_row6_col4" class="data row6 col4">0.7658</td>
      <td id="T_62f96_row6_col5" class="data row6 col5">0.8624</td>
      <td id="T_62f96_row6_col6" class="data row6 col6">0.0316</td>
      <td id="T_62f96_row6_col7" class="data row6 col7">0.0690</td>
      <td id="T_62f96_row6_col8" class="data row6 col8">6.6620</td>
    </tr>
    <tr>
      <th id="T_62f96_level0_row7" class="row_heading level0 row7">lightgbm</th>
      <td id="T_62f96_row7_col0" class="data row7 col0">Light Gradient Boosting Machine</td>
      <td id="T_62f96_row7_col1" class="data row7 col1">0.7583</td>
      <td id="T_62f96_row7_col2" class="data row7 col2">0.6380</td>
      <td id="T_62f96_row7_col3" class="data row7 col3">0.9829</td>
      <td id="T_62f96_row7_col4" class="data row7 col4">0.7661</td>
      <td id="T_62f96_row7_col5" class="data row7 col5">0.8610</td>
      <td id="T_62f96_row7_col6" class="data row7 col6">0.0332</td>
      <td id="T_62f96_row7_col7" class="data row7 col7">0.0675</td>
      <td id="T_62f96_row7_col8" class="data row7 col8">0.1940</td>
    </tr>
    <tr>
      <th id="T_62f96_level0_row8" class="row_heading level0 row8">nb</th>
      <td id="T_62f96_row8_col0" class="data row8 col0">Naive Bayes</td>
      <td id="T_62f96_row8_col1" class="data row8 col1">0.7540</td>
      <td id="T_62f96_row8_col2" class="data row8 col2">0.6470</td>
      <td id="T_62f96_row8_col3" class="data row8 col3">0.9608</td>
      <td id="T_62f96_row8_col4" class="data row8 col4">0.7720</td>
      <td id="T_62f96_row8_col5" class="data row8 col5">0.8561</td>
      <td id="T_62f96_row8_col6" class="data row8 col6">0.0727</td>
      <td id="T_62f96_row8_col7" class="data row8 col7">0.1019</td>
      <td id="T_62f96_row8_col8" class="data row8 col8">0.0250</td>
    </tr>
    <tr>
      <th id="T_62f96_level0_row9" class="row_heading level0 row9">xgboost</th>
      <td id="T_62f96_row9_col0" class="data row9 col0">Extreme Gradient Boosting</td>
      <td id="T_62f96_row9_col1" class="data row9 col1">0.7495</td>
      <td id="T_62f96_row9_col2" class="data row9 col2">0.6231</td>
      <td id="T_62f96_row9_col3" class="data row9 col3">0.9590</td>
      <td id="T_62f96_row9_col4" class="data row9 col4">0.7692</td>
      <td id="T_62f96_row9_col5" class="data row9 col5">0.8537</td>
      <td id="T_62f96_row9_col6" class="data row9 col6">0.0528</td>
      <td id="T_62f96_row9_col7" class="data row9 col7">0.0750</td>
      <td id="T_62f96_row9_col8" class="data row9 col8">0.8160</td>
    </tr>
    <tr>
      <th id="T_62f96_level0_row10" class="row_heading level0 row10">qda</th>
      <td id="T_62f96_row10_col0" class="data row10 col0">Quadratic Discriminant Analysis</td>
      <td id="T_62f96_row10_col1" class="data row10 col1">0.7439</td>
      <td id="T_62f96_row10_col2" class="data row10 col2">0.6441</td>
      <td id="T_62f96_row10_col3" class="data row10 col3">0.9504</td>
      <td id="T_62f96_row10_col4" class="data row10 col4">0.7712</td>
      <td id="T_62f96_row10_col5" class="data row10 col5">0.8465</td>
      <td id="T_62f96_row10_col6" class="data row10 col6">0.0333</td>
      <td id="T_62f96_row10_col7" class="data row10 col7">0.0493</td>
      <td id="T_62f96_row10_col8" class="data row10 col8">0.0190</td>
    </tr>
    <tr>
      <th id="T_62f96_level0_row11" class="row_heading level0 row11">rf</th>
      <td id="T_62f96_row11_col0" class="data row11 col0">Random Forest Classifier</td>
      <td id="T_62f96_row11_col1" class="data row11 col1">0.7233</td>
      <td id="T_62f96_row11_col2" class="data row11 col2">0.5970</td>
      <td id="T_62f96_row11_col3" class="data row11 col3">0.8956</td>
      <td id="T_62f96_row11_col4" class="data row11 col4">0.7758</td>
      <td id="T_62f96_row11_col5" class="data row11 col5">0.8314</td>
      <td id="T_62f96_row11_col6" class="data row11 col6">0.0819</td>
      <td id="T_62f96_row11_col7" class="data row11 col7">0.0892</td>
      <td id="T_62f96_row11_col8" class="data row11 col8">1.3430</td>
    </tr>
    <tr>
      <th id="T_62f96_level0_row12" class="row_heading level0 row12">knn</th>
      <td id="T_62f96_row12_col0" class="data row12 col0">K Neighbors Classifier</td>
      <td id="T_62f96_row12_col1" class="data row12 col1">0.7171</td>
      <td id="T_62f96_row12_col2" class="data row12 col2">0.5745</td>
      <td id="T_62f96_row12_col3" class="data row12 col3">0.8887</td>
      <td id="T_62f96_row12_col4" class="data row12 col4">0.7737</td>
      <td id="T_62f96_row12_col5" class="data row12 col5">0.8272</td>
      <td id="T_62f96_row12_col6" class="data row12 col6">0.0683</td>
      <td id="T_62f96_row12_col7" class="data row12 col7">0.0737</td>
      <td id="T_62f96_row12_col8" class="data row12 col8">0.0930</td>
    </tr>
    <tr>
      <th id="T_62f96_level0_row13" class="row_heading level0 row13">et</th>
      <td id="T_62f96_row13_col0" class="data row13 col0">Extra Trees Classifier</td>
      <td id="T_62f96_row13_col1" class="data row13 col1">0.7058</td>
      <td id="T_62f96_row13_col2" class="data row13 col2">0.5801</td>
      <td id="T_62f96_row13_col3" class="data row13 col3">0.8628</td>
      <td id="T_62f96_row13_col4" class="data row13 col4">0.7760</td>
      <td id="T_62f96_row13_col5" class="data row13 col5">0.8171</td>
      <td id="T_62f96_row13_col6" class="data row13 col6">0.0756</td>
      <td id="T_62f96_row13_col7" class="data row13 col7">0.0786</td>
      <td id="T_62f96_row13_col8" class="data row13 col8">0.6430</td>
    </tr>
    <tr>
      <th id="T_62f96_level0_row14" class="row_heading level0 row14">dt</th>
      <td id="T_62f96_row14_col0" class="data row14 col0">Decision Tree Classifier</td>
      <td id="T_62f96_row14_col1" class="data row14 col1">0.6556</td>
      <td id="T_62f96_row14_col2" class="data row14 col2">0.5333</td>
      <td id="T_62f96_row14_col3" class="data row14 col3">0.7667</td>
      <td id="T_62f96_row14_col4" class="data row14 col4">0.7780</td>
      <td id="T_62f96_row14_col5" class="data row14 col5">0.7723</td>
      <td id="T_62f96_row14_col6" class="data row14 col6">0.0657</td>
      <td id="T_62f96_row14_col7" class="data row14 col7">0.0658</td>
      <td id="T_62f96_row14_col8" class="data row14 col8">0.0740</td>
    </tr>
  </tbody>
</table>

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=227, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The F1 score is a good measure of how well a model is predicting both positive and negative sentiment, the best model for this is 'svm'.</p>
<p>Lets use this model on our test data to see if it seems to be predicting correct sentiment for our reviews.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">'svm'</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">new_predictions</span> <span class="o">=</span> <span class="n">predict_model</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">test</span><span class="p">)</span>
<span class="n">new_predictions</span> <span class="o">=</span> <span class="n">new_predictions</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">amazon_reviews</span><span class="p">)</span>
<span class="n">new_predictions</span> <span class="o">=</span> <span class="n">new_predictions</span><span class="p">[[</span><span class="s1">'reviewText'</span><span class="p">,</span> <span class="s1">'Topic_0'</span><span class="p">,</span> <span class="s1">'Topic_0'</span><span class="p">,</span> <span class="s1">'Topic_0'</span><span class="p">,</span> <span class="s1">'Topic_0'</span><span class="p">,</span> <span class="s1">'Positive'</span><span class="p">,</span> <span class="s1">'Label'</span><span class="p">]]</span>
<span class="n">new_predictions</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>reviewText</th>
      <th>Topic_0</th>
      <th>Topic_0</th>
      <th>Topic_0</th>
      <th>Topic_0</th>
      <th>Positive</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>60</th>
      <td>who doesn't like angrybirds?but the paid version is better as it doesn't have all those annoying adds. blocking your shots!</td>
      <td>0.085445</td>
      <td>0.085445</td>
      <td>0.085445</td>
      <td>0.085445</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>159</th>
      <td>Free and fun, what could be better?  The birds are angry, it's everything I expected, and anyway, those pigs had it coming!</td>
      <td>0.079090</td>
      <td>0.079090</td>
      <td>0.079090</td>
      <td>0.079090</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1294</th>
      <td>I downloaded this to my tablet, as my phone is out of space. Very easy to read the latest tweets that way</td>
      <td>0.118320</td>
      <td>0.118320</td>
      <td>0.118320</td>
      <td>0.118320</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4352</th>
      <td>I love this App and also use Out Of Milk via the website. It makes creating my lists and sharing it with others, quick and easy! It also keeps track of my cost as I add to is, making budgeting a breeze.</td>
      <td>0.081643</td>
      <td>0.081643</td>
      <td>0.081643</td>
      <td>0.081643</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7016</th>
      <td>its actualy saying wat I'm going through. its very fun and creative. I will be sure to use it everyday. no complaints. good job guys. :)</td>
      <td>0.104748</td>
      <td>0.104748</td>
      <td>0.104748</td>
      <td>0.104748</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>'Positive' is our original sentiment for our reviews, and 'Label' is the sentiment predicted by the model. Looking at the first few reviews seems to confirm that our model is able to predict the sentiment of reviews quite well.</p>
<p>This type of text classification or sentiment analysis model could be used for many different types of business application, for example on customer requests to identify complaints. A customer complaints prediction model could be used to classify thousands of customer requests, which could then be used to prioritise customer requests that are flagged as complaints by the model, or pass these on to a specialist team. This could ensure customer complaints were dealt with quickly regardless of how many total customer messages were incoming.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Conclusion">
<a class="anchor" href="#Conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion<a class="anchor-link" href="#Conclusion"> </a>
</h2>
<p>In this article we have looked at the huge benefits NLP applications can bring to businesses. Most state of the art NLP applications use deep learning which often require specialist resources not all businesses will be able or willing initially to support.</p>
<p>We have shown here some examples of how NLP applications without deep learning - such as topic modelling or sentiment analysis and text classification, can bring huge benefits to businesses despite not being state of the art methods, especially for businesses new to Data Science, Machine Learning and AI.</p>

</div>
</div>
</div>
</div>

<script type="application/vnd.jupyter.widget-state+json">
{"54031f3d3e58425c8111f92251763f0f": {"model_module": "@jupyter-widgets/controls", "model_name": "IntProgressModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "", "description": "Processing: ", "description_tooltip": null, "layout": "IPY_MODEL_87dff002b24f47e095d409ccc1d67270", "max": 11, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_8e53cef91b144386aed6eb17fbbf4429", "value": 11}}, "87dff002b24f47e095d409ccc1d67270": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "8e53cef91b144386aed6eb17fbbf4429": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "eb5912f2b5744dc78e24e155e63a4a8b": {"model_module": "@jupyter-widgets/controls", "model_name": "IntProgressModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "", "description": "Processing: ", "description_tooltip": null, "layout": "IPY_MODEL_49e1bb466033406e930431fc51b62d12", "max": 4, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_c031bb3be83c4cc4a053b215c2a9ec30", "value": 4}}, "49e1bb466033406e930431fc51b62d12": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c031bb3be83c4cc4a053b215c2a9ec30": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "1b039c053bdc4f528de7123df5b9a19a": {"model_module": "@jupyter-widgets/controls", "model_name": "IntProgressModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "", "description": "Processing: ", "description_tooltip": null, "layout": "IPY_MODEL_d4bd5eb1e58947588d31f5cfb195eb4c", "max": 20005, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_5e6ce698b5464b4c834bd8aadf3937d2", "value": 18339}}, "d4bd5eb1e58947588d31f5cfb195eb4c": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "5e6ce698b5464b4c834bd8aadf3937d2": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}}
</script>



  </div>
  
  <a class="u-url" href="/pycaret/natural-language-processing/2023/01/08/nlp-text-classification-without-deep-learning-for-business-applications.html" hidden></a>
</article><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="pranath/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">
    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"></ul>
</div>

  </div>

</footer>
<script type="text/javascript" src="/js/lightbox.js"></script>
<link rel="stylesheet" href="/css/lightbox.css">
</body>

</html>
