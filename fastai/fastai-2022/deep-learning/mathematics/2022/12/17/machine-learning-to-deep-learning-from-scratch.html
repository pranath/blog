<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>From Machine Learning to Deep Learning From Scratch | livingdatalab</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="From Machine Learning to Deep Learning From Scratch" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="What’s the difference between machine learning and deep learning? In this article we will explain the differences between machine learning &amp; deep learning, and will illustrate this by building a machine learning and a deep learning model from scratch." />
<meta property="og:description" content="What’s the difference between machine learning and deep learning? In this article we will explain the differences between machine learning &amp; deep learning, and will illustrate this by building a machine learning and a deep learning model from scratch." />
<link rel="canonical" href="https://www.livingdatalab.com/fastai/fastai-2022/deep-learning/mathematics/2022/12/17/machine-learning-to-deep-learning-from-scratch.html" />
<meta property="og:url" content="https://www.livingdatalab.com/fastai/fastai-2022/deep-learning/mathematics/2022/12/17/machine-learning-to-deep-learning-from-scratch.html" />
<meta property="og:site_name" content="livingdatalab" />
<meta property="og:image" content="https://www.livingdatalab.com/images/ml_v_dl.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-12-17T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://www.livingdatalab.com/fastai/fastai-2022/deep-learning/mathematics/2022/12/17/machine-learning-to-deep-learning-from-scratch.html","@type":"BlogPosting","headline":"From Machine Learning to Deep Learning From Scratch","dateModified":"2022-12-17T00:00:00-06:00","datePublished":"2022-12-17T00:00:00-06:00","image":"https://www.livingdatalab.com/images/ml_v_dl.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.livingdatalab.com/fastai/fastai-2022/deep-learning/mathematics/2022/12/17/machine-learning-to-deep-learning-from-scratch.html"},"description":"What’s the difference between machine learning and deep learning? In this article we will explain the differences between machine learning &amp; deep learning, and will illustrate this by building a machine learning and a deep learning model from scratch.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://www.livingdatalab.com/feed.xml" title="livingdatalab" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-91568149-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">livingdatalab</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Livingdatalab</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">From Machine Learning to Deep Learning From Scratch</h1><p class="page-description">What's the difference between machine learning and deep learning? In this article we will explain the differences between machine learning & deep learning, and will illustrate this by building a machine learning and a deep learning model from scratch.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-12-17T00:00:00-06:00" itemprop="datePublished">
        Dec 17, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      28 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#fastai">fastai</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#fastai-2022">fastai-2022</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#deep-learning">deep-learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#mathematics">mathematics</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          
          
          
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Introduction">Introduction </a></li>
<li class="toc-entry toc-h2"><a href="#Machine-Learning-vs-Deep-Learning">Machine Learning vs Deep Learning </a></li>
<li class="toc-entry toc-h2"><a href="#The-Dataset:-The-Kaggle-Titanic-passenger-suvival-dataset">The Dataset: The Kaggle Titanic passenger suvival dataset </a></li>
<li class="toc-entry toc-h2"><a href="#Import-Libraries">Import Libraries </a></li>
<li class="toc-entry toc-h2"><a href="#Get-&-Clean-Data">Get &amp; Clean Data </a></li>
<li class="toc-entry toc-h2"><a href="#Creating-a-Linear-Model">Creating a Linear Model </a>
<ul>
<li class="toc-entry toc-h3"><a href="#How-our-Linear-Model-Learns---Adding-Gradient-Descent">How our Linear Model Learns - Adding Gradient Descent </a></li>
<li class="toc-entry toc-h3"><a href="#Training-the-Linear-Model">Training the Linear Model </a></li>
<li class="toc-entry toc-h3"><a href="#Checking-Model-Accuracy">Checking Model Accuracy </a></li>
<li class="toc-entry toc-h3"><a href="#Improving-Model-Predictions-with-a-Sigmoid-Function">Improving Model Predictions with a Sigmoid Function </a></li>
<li class="toc-entry toc-h3"><a href="#Improving-the-Maths---Using-Matrix-Multiplications">Improving the Maths - Using Matrix Multiplications </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Creating-a-Neural-Network-Model">Creating a Neural Network Model </a></li>
<li class="toc-entry toc-h2"><a href="#Creating-a-Deep-Learning-Model">Creating a Deep Learning Model </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-12-17-machine-learning-to-deep-learning-from-scratch.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction">
<a class="anchor" href="#Introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction<a class="anchor-link" href="#Introduction"> </a>
</h2>
<p>In this series of articles I will be re-visiting the <a href="https://course.fast.ai/">FastAI Practical Deep Learning for Coders</a> course for <a href="https://livingdatalab.com/categories/#fastai-2022">this year 2022</a> which I have completed in <a href="https://livingdatalab.com/categories/#fastai">previous years</a>. This article covers lesson 5 of this years course, where we will look at the fundemental details and differences between machine learning (ml) and deep learning (dl).</p>
<p>If you don't understand the difference between ml and dl or were too afraid to ask - this is the article for you!</p>
<h2 id="Machine-Learning-vs-Deep-Learning">
<a class="anchor" href="#Machine-Learning-vs-Deep-Learning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Machine Learning vs Deep Learning<a class="anchor-link" href="#Machine-Learning-vs-Deep-Learning"> </a>
</h2>
<p><a href="https://en.wikipedia.org/wiki/Machine_learning">Machine Learning</a> is a branch of computer science that seeks to create systems (often called 'models') that learn how to perform a task, without being given explicit instructions of how to perform that task. These models learn for themselves how to perform a task. Machine Learning includes a wide range of different types of models, for example linear regression, random forrests, and more.</p>
<p><a href="https://en.wikipedia.org/wiki/Deep_learning">Deep learning</a> is a sub-branch of machine learning, which uses <strong>multi-layered artifical neural networks</strong> as models that learn how to perform a task, without being given explicit instructions of how to perform that task.</p>
<p>Other notable differences between machine learning and deep learning include:</p>
<ul>
<li>Machine learning models tend to be easier to understand and explain why they do what they do, deep learning models tend to be more difficult to understand the reasons for their behaviour</li>
<li>Machine learning models tend to require the data they use to be more carefully constructed, deep learning models tend to be able to work with data that does not need to be so carefully created</li>
<li>Deep learning models are much more powerful and succesful than machine learning models at solving problems that use images or text</li>
</ul>
<p><a href="https://www.zendesk.co.uk/blog/machine-learning-and-deep-learning/">This article</a> also further explains these differences.</p>
<p>In this project we will construct from scratch a very simple machine learning model called <em>linear regression</em>. We will then gradually develop a deep learning model from scratch, and we will illustrate the technical differences between these types of models, which also demonstrates the reasons for the differences between the two types of models highlighted above.</p>
<p>We will not use any machine learning libraries, which often obscure the details of how these models are implemented. <strong>In this project, we will expose the fundemental details of these models by coding them manually and illustrating the mathematics behind them.</strong></p>
<h2 id="The-Dataset:-The-Kaggle-Titanic-passenger-suvival-dataset">
<a class="anchor" href="#The-Dataset:-The-Kaggle-Titanic-passenger-suvival-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Dataset: The Kaggle Titanic passenger suvival dataset<a class="anchor-link" href="#The-Dataset:-The-Kaggle-Titanic-passenger-suvival-dataset"> </a>
</h2>
<p>For our project we will use the famous <a href="https://www.kaggle.com/competitions/titanic/data">Titanic - Machine Learning from Disaster dataset</a>. This is a dataset of the passengers from the Titanic disaster, and the task is to predict which of these passengers died and which survived.</p>
<p>This is a very simple and well known dataset, and is chosen not because it's an especially challenging task, but more to allow us to understand the differences between machine learning and deep learning.</p>
<h2 id="Import-Libraries">
<a class="anchor" href="#Import-Libraries" aria-hidden="true"><span class="octicon octicon-link"></span></a>Import Libraries<a class="anchor-link" href="#Import-Libraries"> </a>
</h2>
<p>First we will import the required libraries.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">from</span> <span class="nn">fastai.data.transforms</span> <span class="kn">import</span> <span class="n">RandomSplitter</span>
<span class="kn">import</span> <span class="nn">sympy</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="c1"># Set some useful display settings</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">140</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">140</span><span class="p">,</span> <span class="n">sci_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">edgeitems</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">'display.width'</span><span class="p">,</span> <span class="mi">140</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Get-&amp;-Clean-Data">
<a class="anchor" href="#Get-&amp;-Clean-Data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Get &amp; Clean Data<a class="anchor-link" href="#Get-&amp;-Clean-Data"> </a>
</h2>
<p>Let's now extract the data and examine what it looks like.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">unzip</span> <span class="n">titanic</span><span class="o">.</span><span class="n">zip</span>
<span class="err">!</span><span class="n">ls</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Archive:  titanic.zip
  inflating: gender_submission.csv   
  inflating: test.csv                
  inflating: train.csv               
drive  gender_submission.csv  sample_data  test.csv  titanic.zip  train.csv
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'train.csv'</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">

  <div id="df-867e4e87-7df7-47b4-8bb4-e7597a986f45">
    <div class="colab-df-container">
      <div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-867e4e87-7df7-47b4-8bb4-e7597a986f45')" title="Convert this dataframe to an interactive table." style="display:none;">
        
  &lt;svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px"&gt;
    <path d="M0 0h24v24H0V0z" fill="none"></path>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"></path><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"></path>
  &lt;/svg&gt;
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-867e4e87-7df7-47b4-8bb4-e7597a986f45 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-867e4e87-7df7-47b4-8bb4-e7597a986f45');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we can see the different columns in our passenger dataset, for example Name, Sex, Age etc. The <strong>Survived</strong> column tells us if that passenger survived the disaster, with a value of 1 if they did and a value of 0 if they died. This is the value we want our model to predict, given the other data in the dataset. In other words, we want to create a model to predict <strong>Survived</strong> based on Name, Age, Ticket, Fare etc.</p>
<p>Machine learning models require the data to be all numbers, they can't work with missing values. Let's check to see if we have any missing values in our dataet the textual columns of the data. The <em>isna()</em> function will do this for us in python.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>PassengerId      0
Survived         0
Pclass           0
Name             0
Sex              0
Age            177
SibSp            0
Parch            0
Ticket           0
Fare             0
Cabin          687
Embarked         2
dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see that the Age, Cabin and Embarked columns have missing values, so we will need to do something about these. Let's replace the missing values with the most common value in that column, this is known in statistics as the <em>mode</em>.</p>
<p>Lets calculate the mode for each column.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">modes</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">mode</span><span class="p">()</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">modes</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>PassengerId                      1
Survived                       0.0
Pclass                         3.0
Name           Abbing, Mr. Anthony
Sex                           male
Age                           24.0
SibSp                          0.0
Parch                          0.0
Ticket                        1601
Fare                          8.05
Cabin                      B96 B98
Embarked                         S
Name: 0, dtype: object</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have the mode of each column, we can use these to fill in the missing values of any column using the <em>fillna()</em> function.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">modes</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's check to see we no longer have any missing values.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>PassengerId    0
Survived       0
Pclass         0
Name           0
Sex            0
Age            0
SibSp          0
Parch          0
Ticket         0
Fare           0
Cabin          0
Embarked       0
dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As mentioned earlier, machine learning models require numbers as inputs - so we will need to convert our text fields into numeric fields. We can do this using a standard technique called <a href="https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/">one-hot encoding</a> which creates a numeric column for each text value which are called <em>dummy variables</em> which has a value of 1 or zero depending if that text/category value is present or not. We can create these fields using the <em>get_dummies()</em> method.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"Sex"</span><span class="p">,</span><span class="s2">"Pclass"</span><span class="p">,</span><span class="s2">"Embarked"</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Index(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'LogFare', 'Sex_female', 'Sex_male',
       'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],
      dtype='object')</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's see what these dummy variable columns look like.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">added_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Sex_male'</span><span class="p">,</span> <span class="s1">'Sex_female'</span><span class="p">,</span> <span class="s1">'Pclass_1'</span><span class="p">,</span> <span class="s1">'Pclass_2'</span><span class="p">,</span> <span class="s1">'Pclass_3'</span><span class="p">,</span> <span class="s1">'Embarked_C'</span><span class="p">,</span> <span class="s1">'Embarked_Q'</span><span class="p">,</span> <span class="s1">'Embarked_S'</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="n">added_cols</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">

  <div id="df-98862631-ba13-4396-a92b-487ebc4f9bd5">
    <div class="colab-df-container">
      <div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Sex_male</th>
      <th>Sex_female</th>
      <th>Pclass_1</th>
      <th>Pclass_2</th>
      <th>Pclass_3</th>
      <th>Embarked_C</th>
      <th>Embarked_Q</th>
      <th>Embarked_S</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-98862631-ba13-4396-a92b-487ebc4f9bd5')" title="Convert this dataframe to an interactive table." style="display:none;">
        
  &lt;svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px"&gt;
    <path d="M0 0h24v24H0V0z" fill="none"></path>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"></path><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"></path>
  &lt;/svg&gt;
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-98862631-ba13-4396-a92b-487ebc4f9bd5 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-98862631-ba13-4396-a92b-487ebc4f9bd5');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we will need to convert our model variables into Pytorch tensors, which will enable us to use our data for both machine learning and deep learning later on.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">t_dep</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Survived</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">indep_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Age'</span><span class="p">,</span> <span class="s1">'SibSp'</span><span class="p">,</span> <span class="s1">'Parch'</span><span class="p">,</span> <span class="s1">'LogFare'</span><span class="p">]</span> <span class="o">+</span> <span class="n">added_cols</span>

<span class="n">t_indep</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">indep_cols</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="n">t_indep</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[22.0000,  1.0000,  0.0000,  2.1102,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],
        [38.0000,  1.0000,  0.0000,  4.2806,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],
        [26.0000,  0.0000,  0.0000,  2.1889,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],
        [35.0000,  1.0000,  0.0000,  3.9908,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],
        [35.0000,  0.0000,  0.0000,  2.2028,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],
        [24.0000,  0.0000,  0.0000,  2.2469,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],
        [54.0000,  0.0000,  0.0000,  3.9677,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],
        ...,
        [25.0000,  0.0000,  0.0000,  2.0857,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],
        [39.0000,  0.0000,  5.0000,  3.4054,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],
        [27.0000,  0.0000,  0.0000,  2.6391,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],
        [19.0000,  0.0000,  0.0000,  3.4340,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],
        [24.0000,  1.0000,  2.0000,  3.1966,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],
        [26.0000,  0.0000,  0.0000,  3.4340,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],
        [32.0000,  0.0000,  0.0000,  2.1691,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000]])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">t_indep</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([891, 12])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Creating-a-Linear-Model">
<a class="anchor" href="#Creating-a-Linear-Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating a Linear Model<a class="anchor-link" href="#Creating-a-Linear-Model"> </a>
</h2>
<p>A simple linear regression model attempts to capture a linear relationship betweeen one independant variable and a dependant variable, so that you can predict the latter using the former. In our example below, the independant variable model coefficient is $b_{1}$. A constant value is also added, in this case $b_{0}$. This is basically the equation of a line.</p>
<p>A multiple linear regression model attempts to capture a linear relationship betweeen <strong>multiple</strong> independant variables and a dependant variable, so that you can predict the latter using the former. In our example below, the independant variable model coefficients are $b_{0}$ to $b_{n}$. This is basically the equation of a <a href="https://kindsonthegenius.com/blog/what-is-a-linear-seperator-what-is-a-hyperplane-simple-and-brief-explanation/">hyperplane</a> which is a line in multiple dimensions, in this case that number is the number of independant variables.</p>
<p>The values of the independant variables themselves are represented by $x_{1}$ to $x_{n}$.</p>
<p>Linear models generate their predictions by multiplying the values of each variable by its coefficient, then summing the values. So for our multiple linear regression model that would mean summing $b_{1}$ <em> $x_{1}$ to $b_{n}$ </em> $x_{n}$ then adding the constant term $b_{0}$ to get the value for the dependant variable y.</p>
<p>You can read more about <a href="https://levelup.gitconnected.com/beginners-guide-to-simple-and-multiple-linear-regression-models-d2d5dbe9e704">linear regression here</a>.</p>
<p><img src="https://github.com/pranath/blog/raw/master/images/linear_reg.png" alt="" title="Simple &amp; Multiple Linear Regression"></p>
<p>For our titanic dataset, we have multiple independant variables such as passenger id, name, fare etc - so we will need to use a multiple linear regression model, which will have a coefficient for each variable we have.</p>
<p>Let's set up some coefficient's for each variable with some random initial values.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">442</span><span class="p">)</span>

<span class="n">n_coeff</span> <span class="o">=</span> <span class="n">t_indep</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">coeffs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_coeff</span><span class="p">)</span><span class="o">-</span><span class="mf">0.5</span>
<span class="n">coeffs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Interestingly we don't need to add a constant term as per the linear regression model equation. Why? because our dummy variables already cover the whole dataset, everyone is already within one existing value eg male or female. So we don't need a separate constant term to cover any rows not included.</p>
<p>As mentioned, a linear model will calculate its predictions by multiplying the independant variables by their corresponding coefficients so lets see what that looks like. Remember we have multiple values of our independant variables, one row per passenger, so a matrix. So we will expect from linear algebra, when we multiply a vector (coefficients) by a matrix we should end up with a new matrix.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">t_indep</span><span class="o">*</span><span class="n">coeffs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[-10.1838,   0.1386,   0.0000,  -0.4772,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],
        [-17.5902,   0.1386,   0.0000,  -0.9681,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.4392,   0.0000,   0.0000],
        [-12.0354,   0.0000,   0.0000,  -0.4950,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],
        [-16.2015,   0.1386,   0.0000,  -0.9025,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],
        [-16.2015,   0.0000,   0.0000,  -0.4982,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],
        [-11.1096,   0.0000,   0.0000,  -0.5081,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000],
        [-24.9966,   0.0000,   0.0000,  -0.8973,  -0.2632,  -0.0000,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],
        ...,
        [-11.5725,   0.0000,   0.0000,  -0.4717,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],
        [-18.0531,   0.0000,   1.2045,  -0.7701,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000],
        [-12.4983,   0.0000,   0.0000,  -0.5968,  -0.2632,  -0.0000,   0.0000,   0.3136,   0.0000,  -0.0000,   0.0000,   0.3625],
        [ -8.7951,   0.0000,   0.0000,  -0.7766,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],
        [-11.1096,   0.1386,   0.4818,  -0.7229,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],
        [-12.0354,   0.0000,   0.0000,  -0.7766,  -0.2632,  -0.0000,   0.4876,   0.0000,   0.0000,  -0.4392,   0.0000,   0.0000],
        [-14.8128,   0.0000,   0.0000,  -0.4905,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000]])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So there is a bit of an issue here, we notice the first column has much bigger values? this is for the column age, which has bigger numbers than all other numeric columns. This can create problems for machine learning, as many models will treat the column with bigger numbers as more important than other columns.</p>
<p>We can address this issue by <em>normalising</em> all the values i.e. dividing each column by its maximum value. This will result in all values being bewteen 1 and 0 and so all variables being treated with equal importance.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">vals</span><span class="p">,</span><span class="n">indices</span> <span class="o">=</span> <span class="n">t_indep</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">t_indep</span> <span class="o">=</span> <span class="n">t_indep</span> <span class="o">/</span> <span class="n">vals</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">t_indep</span><span class="o">*</span><span class="n">coeffs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[-0.1273,  0.0173,  0.0000, -0.0765, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],
        [-0.2199,  0.0173,  0.0000, -0.1551, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.4392,  0.0000,  0.0000],
        [-0.1504,  0.0000,  0.0000, -0.0793, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],
        [-0.2025,  0.0173,  0.0000, -0.1446, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],
        [-0.2025,  0.0000,  0.0000, -0.0798, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],
        [-0.1389,  0.0000,  0.0000, -0.0814, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000],
        [-0.3125,  0.0000,  0.0000, -0.1438, -0.2632, -0.0000,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],
        ...,
        [-0.1447,  0.0000,  0.0000, -0.0756, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],
        [-0.2257,  0.0000,  0.2008, -0.1234, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000],
        [-0.1562,  0.0000,  0.0000, -0.0956, -0.2632, -0.0000,  0.0000,  0.3136,  0.0000, -0.0000,  0.0000,  0.3625],
        [-0.1099,  0.0000,  0.0000, -0.1244, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],
        [-0.1389,  0.0173,  0.0803, -0.1158, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],
        [-0.1504,  0.0000,  0.0000, -0.1244, -0.2632, -0.0000,  0.4876,  0.0000,  0.0000, -0.4392,  0.0000,  0.0000],
        [-0.1852,  0.0000,  0.0000, -0.0786, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000]])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can now create predictions from our linear model, by adding up the rows of the product:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">preds</span> <span class="o">=</span> <span class="p">(</span><span class="n">t_indep</span><span class="o">*</span><span class="n">coeffs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's take a look at the first few:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">preds</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([ 0.1927, -0.6239,  0.0979,  0.2056,  0.0968,  0.0066,  0.1306,  0.3476,  0.1613, -0.6285])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="How-our-Linear-Model-Learns---Adding-Gradient-Descent">
<a class="anchor" href="#How-our-Linear-Model-Learns---Adding-Gradient-Descent" aria-hidden="true"><span class="octicon octicon-link"></span></a>How our Linear Model Learns - Adding Gradient Descent<a class="anchor-link" href="#How-our-Linear-Model-Learns---Adding-Gradient-Descent"> </a>
</h3>
<p>So currently we have a basic linear model, but it is'nt predicting very well because the model coefficients are still random values. How can make these coefficients better so our model predictions can get better? we can use a algorithm called <strong>Gradient Descent (or GD)</strong>.</p>
<p><a href="https://builtin.com/data-science/gradient-descent">This article explains the fundamentals of GD</a>. And <a href="https://towardsdatascience.com/understanding-the-mathematics-behind-gradient-descent-dde5dc9be06e">this article</a> as well as <a href="https://medium.com/geekculture/mathematics-behind-gradient-descent-f2a49a0b714f">this one</a> explain more the mathematics of GD.</p>
<p>In essence, <strong>Gradient Descent is an algorithm that can be used to find values for the coefficients of a function that reduce a separate loss function</strong>. So as long as we can define an appropriate loss function, we can use this algorithm.</p>
<p>What would be an appropriate loss function that we would want to minimise the value of? Well we would like our predictions ultimately to be as close to the actual values we want to predict. So here the loss would be <em>a measure of how wrong our predictions are</em>. A high loss value would mean many mistakes, and a low loss value would mean fewer mistakes. This would then be a good function for us to minimise using Gradient Descent.</p>
<p>So in our case, a good loss function might be:</p>
<p><em>Loss = predictions - values we want to predict</em></p>
<p>So we will have a different loss value for each value and its prediction, so if we took the mean value of all of these different loss values, that would be a way to capture the overall loss for all predictions. It would also be helpful for these differences to be always positive values.</p>
<p>Lets calculate what this loss would be on our current predictions.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">preds</span><span class="o">-</span><span class="n">t_dep</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">loss</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(0.5382)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since for Gradient Descent we will need to repeatedly use this loss function, lets define some functions to calculate our predictions as well as the loss.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">calc_preds</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">indeps</span><span class="p">):</span> 
  <span class="k">return</span> <span class="p">(</span><span class="n">indeps</span><span class="o">*</span><span class="n">coeffs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">calc_loss</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">indeps</span><span class="p">,</span> <span class="n">deps</span><span class="p">):</span> 
  <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">calc_preds</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">indeps</span><span class="p">)</span><span class="o">-</span><span class="n">deps</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Gradient Descent requires us to calculate gradients. These are the values of the derivatives of the functions that generate the predictions so in our case the derviatives of the multiple linear regression function seen earlier. The Pytorch module can calculate these gradients for us every time the linear regression function is used if we set <em>requires_grad()</em> on the model coefficients. Lets do that now.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">coeffs</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625], requires_grad=True)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's now calculate the loss for our current predictions again using our new function.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">calc_loss</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">t_indep</span><span class="p">,</span> <span class="n">t_dep</span><span class="p">)</span>
<span class="n">loss</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(0.5382, grad_fn=&lt;MeanBackward0&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can now ask Pytorch to calculate our gradients now using <em>backward()</em>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's have a look at the gradients calculated for our model coefficients.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">coeffs</span><span class="o">.</span><span class="n">grad</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([-0.0106,  0.0129, -0.0041, -0.0484,  0.2099, -0.2132, -0.1212, -0.0247,  0.1425, -0.1886, -0.0191,  0.2043])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>These gradients tell us how much we need to change each model coefficient to reduce the loss function i.e. to improve the predictions.</p>
<p>So putting these steps together:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">calc_loss</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">t_indep</span><span class="p">,</span> <span class="n">t_dep</span><span class="p">)</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">coeffs</span><span class="o">.</span><span class="n">grad</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([-0.0212,  0.0258, -0.0082, -0.0969,  0.4198, -0.4265, -0.2424, -0.0494,  0.2851, -0.3771, -0.0382,  0.4085])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see our gradient values have doubled? this ie because every time <em>backward()</em> is called it adds the new gradients to the previous ones. We don't want this, as we only want the gradients that pertain to the current model coefficients, not the previous ones.</p>
<p>So what we really want to do is reset the gradient values to zero after each step of the gradient descent process.</p>
<p>Lets define some code to put this all together, and print our current loss value.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Calculate loss</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">calc_loss</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">t_indep</span><span class="p">,</span> <span class="n">t_dep</span><span class="p">)</span>
<span class="c1"># Calculate gradients of linear model e.g. coeffs * inputs</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="c1"># Don't calculate any gradients here</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="c1"># Subtract the gradients from the model coeffcients to improve them, but scale this update by 0.1 called the 'learning rate'</span>
    <span class="n">coeffs</span><span class="o">.</span><span class="n">sub_</span><span class="p">(</span><span class="n">coeffs</span><span class="o">.</span><span class="n">grad</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="c1"># Set gradients to zero</span>
    <span class="n">coeffs</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
    <span class="c1"># Print current loss</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">calc_loss</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">t_indep</span><span class="p">,</span> <span class="n">t_dep</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor(0.4945)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The learning rate i used to ensure we take small steps of improvement for the cofficients, rather than big steps. To better understand why and how gradient decent works in more detail <a href="https://builtin.com/data-science/gradient-descent">this article explains the fundamentals of GD</a>. And <a href="https://towardsdatascience.com/understanding-the-mathematics-behind-gradient-descent-dde5dc9be06e">this article</a> as well as <a href="https://medium.com/geekculture/mathematics-behind-gradient-descent-f2a49a0b714f">this one</a> explain more the mathematics of GD.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Training-the-Linear-Model">
<a class="anchor" href="#Training-the-Linear-Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Training the Linear Model<a class="anchor-link" href="#Training-the-Linear-Model"> </a>
</h3>
<p>Before we can train our model we need to split our data into training and validation sets. We can use <em>RandomSplitter()</em> to do this.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">trn_split</span><span class="p">,</span><span class="n">val_split</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)(</span><span class="n">df</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">trn_indep</span><span class="p">,</span><span class="n">val_indep</span> <span class="o">=</span> <span class="n">t_indep</span><span class="p">[</span><span class="n">trn_split</span><span class="p">],</span><span class="n">t_indep</span><span class="p">[</span><span class="n">val_split</span><span class="p">]</span>
<span class="n">trn_dep</span><span class="p">,</span><span class="n">val_dep</span> <span class="o">=</span> <span class="n">t_dep</span><span class="p">[</span><span class="n">trn_split</span><span class="p">],</span><span class="n">t_dep</span><span class="p">[</span><span class="n">val_split</span><span class="p">]</span>
<span class="nb">len</span><span class="p">(</span><span class="n">trn_indep</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">val_indep</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(713, 178)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll also create functions for the three things we did manually above: updating coeffs, doing one full gradient descent step, and initilising coeffs to random numbers.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">update_coeffs</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
    <span class="n">coeffs</span><span class="o">.</span><span class="n">sub_</span><span class="p">(</span><span class="n">coeffs</span><span class="o">.</span><span class="n">grad</span> <span class="o">*</span> <span class="n">lr</span><span class="p">)</span>
    <span class="n">coeffs</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">one_epoch</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">calc_loss</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">trn_indep</span><span class="p">,</span> <span class="n">trn_dep</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="n">update_coeffs</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">"; "</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">init_coeffs</span><span class="p">():</span> 
    <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_coeff</span><span class="p">)</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's now create a function do train the model. We will initialise the model coefficients to random values, then loop through one epoch to calculate the loss and gradients, and update the coefficients. An <em>epoch</em> is the model generating precdictions for the entire training dataet. So the training process is multiple epochs/loops over the training data, updating the model coefficients in each loop. <strong>This is the gradient descent algorithm</strong>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">442</span><span class="p">)</span>
    <span class="n">coeffs</span> <span class="o">=</span> <span class="n">init_coeffs</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span> <span class="n">one_epoch</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">coeffs</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets choose a learning rate of 0.2 and train our model for 18 epochs. What we hope to see is out loss value go down in each epoch, as the model coefficients are updated to get better and improve the predictions.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">coeffs</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.536; 0.502; 0.477; 0.454; 0.431; 0.409; 0.388; 0.367; 0.349; 0.336; 0.330; 0.326; 0.329; 0.304; 0.314; 0.296; 0.300; 0.289; </pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see here as expected, the loss is going down and the predictions are improving with each epoch.</p>
<p>This means that the model coefficients for each of the input variables is getting better, or more accurate. Lets have a look at the improved coefficients so far.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">show_coeffs</span><span class="p">():</span> 
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">indep_cols</span><span class="p">,</span> <span class="n">coeffs</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)))</span>
<span class="n">show_coeffs</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{'Age': tensor(-0.2694),
 'SibSp': tensor(0.0901),
 'Parch': tensor(0.2359),
 'LogFare': tensor(0.0280),
 'Sex_male': tensor(-0.3990),
 'Sex_female': tensor(0.2345),
 'Pclass_1': tensor(0.7232),
 'Pclass_2': tensor(0.4112),
 'Pclass_3': tensor(0.3601),
 'Embarked_C': tensor(0.0955),
 'Embarked_Q': tensor(0.2395),
 'Embarked_S': tensor(0.2122)}</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Checking-Model-Accuracy">
<a class="anchor" href="#Checking-Model-Accuracy" aria-hidden="true"><span class="octicon octicon-link"></span></a>Checking Model Accuracy<a class="anchor-link" href="#Checking-Model-Accuracy"> </a>
</h3>
<p>So the loss value is giving us a good indication of how well our model is improving. But it's not perhaps what we want as our ultimate measure of the model performance. For the kaggle competition, the desire measure of performance is <em>accuracy</em> i.e.</p>
<p>Accuracy = Correct Predictions / Total Predictions</p>
<p>Lets first get the predictions.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">preds</span> <span class="o">=</span> <span class="n">calc_preds</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">val_indep</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We want a simple category of True if the passenger died, and False if they survived. To convert our predictions into these values we will use a threshold of 0.5 to decide which converts to which.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">val_dep</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span><span class="o">==</span><span class="p">(</span><span class="n">preds</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">results</span><span class="p">[:</span><span class="mi">16</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True, False, False, False,  True,  True, False])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's now calculate the accuracy.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">acc</span><span class="p">(</span><span class="n">coeffs</span><span class="p">):</span> 
    <span class="k">return</span> <span class="p">(</span><span class="n">val_dep</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span><span class="o">==</span><span class="p">(</span><span class="n">calc_preds</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">val_indep</span><span class="p">)</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">acc</span><span class="p">(</span><span class="n">coeffs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(0.7865)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Improving-Model-Predictions-with-a-Sigmoid-Function">
<a class="anchor" href="#Improving-Model-Predictions-with-a-Sigmoid-Function" aria-hidden="true"><span class="octicon octicon-link"></span></a>Improving Model Predictions with a Sigmoid Function<a class="anchor-link" href="#Improving-Model-Predictions-with-a-Sigmoid-Function"> </a>
</h3>
<p>If we look at our predictions, they could easily have values bigger that 1 or less than zero.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">preds</span><span class="p">[:</span><span class="mi">28</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([ 0.8160,  0.1295, -0.0148,  0.1831,  0.1520,  0.1350,  0.7279,  0.7754,  0.3222,  0.6740,  0.0753,  0.0389,  0.2216,  0.7631,
         0.0678,  0.3997,  0.3324,  0.8278,  0.1078,  0.7126,  0.1023,  0.3627,  0.9937,  0.8050,  0.1153,  0.1455,  0.8652,  0.3425])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We want these predictions to be only from 0-1. If we pass these predictions through a <em>sigmoid function</em> that will achieve this.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">sympy</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="s2">"1/(1+exp(-x))"</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">));</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's now improve our predictions function using this.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">calc_preds</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">indeps</span><span class="p">):</span> 
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">((</span><span class="n">indeps</span><span class="o">*</span><span class="n">coeffs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And now lets train the model again.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">coeffs</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.510; 0.327; 0.294; 0.207; 0.201; 0.199; 0.198; 0.197; 0.196; 0.196; 0.196; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; </pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This has really improved the loss which is falling much more. Let's check the accuracy.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">acc</span><span class="p">(</span><span class="n">coeffs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(0.8258)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This has also improved a lot.</p>
<p>Lets look at the model coefficients.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">show_coeffs</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{'Age': tensor(-1.5061),
 'SibSp': tensor(-1.1575),
 'Parch': tensor(-0.4267),
 'LogFare': tensor(0.2543),
 'Sex_male': tensor(-10.3320),
 'Sex_female': tensor(8.4185),
 'Pclass_1': tensor(3.8389),
 'Pclass_2': tensor(2.1398),
 'Pclass_3': tensor(-6.2331),
 'Embarked_C': tensor(1.4771),
 'Embarked_Q': tensor(2.1168),
 'Embarked_S': tensor(-4.7958)}</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Do these values make sense? these coefficients suggest what are the most important features useful for predicting survival. We can see that Sex_male has a big negative value, which implies a negative association. We can also see age is negatively associated. Taken together, these two coefficients suggest that males and older people were less likely to survive the titantic disaster.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Improving-the-Maths---Using-Matrix-Multiplications">
<a class="anchor" href="#Improving-the-Maths---Using-Matrix-Multiplications" aria-hidden="true"><span class="octicon octicon-link"></span></a>Improving the Maths - Using Matrix Multiplications<a class="anchor-link" href="#Improving-the-Maths---Using-Matrix-Multiplications"> </a>
</h3>
<p>Is there a way we can improve the calculations to make things more efficient? if we look again at the biggest calculation to make predictions.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="p">(</span><span class="n">val_indep</span><span class="o">*</span><span class="n">coeffs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([ 12.3288, -14.8119, -15.4540, -13.1513, -13.3512, -13.6469,   3.6248,   5.3429, -22.0878,   3.1233, -21.8742, -15.6421, -21.5504,
          3.9393, -21.9190, -12.0010, -12.3775,   5.3550, -13.5880,  -3.1015, -21.7237, -12.2081,  12.9767,   4.7427, -21.6525, -14.9135,
         -2.7433, -12.3210, -21.5886,   3.9387,   5.3890,  -3.6196, -21.6296, -21.8454,  12.2159,  -3.2275, -12.0289,  13.4560, -21.7230,
         -3.1366, -13.2462, -21.7230, -13.6831,  13.3092, -21.6477,  -3.5868, -21.6854, -21.8316, -14.8158,  -2.9386,  -5.3103, -22.2384,
        -22.1097, -21.7466, -13.3780, -13.4909, -14.8119, -22.0690, -21.6666, -21.7818,  -5.4439, -21.7407, -12.6551, -21.6671,   4.9238,
        -11.5777, -13.3323, -21.9638, -15.3030,   5.0243, -21.7614,   3.1820, -13.4721, -21.7170, -11.6066, -21.5737, -21.7230, -11.9652,
        -13.2382, -13.7599, -13.2170,  13.1347, -21.7049, -21.7268,   4.9207,  -7.3198,  -5.3081,   7.1065,  11.4948, -13.3135, -21.8723,
        -21.7230,  13.3603, -15.5670,   3.4105,  -7.2857, -13.7197,   3.6909,   3.9763, -14.7227, -21.8268,   3.9387, -21.8743, -21.8367,
        -11.8518, -13.6712, -21.8299,   4.9440,  -5.4471, -21.9666,   5.1333,  -3.2187, -11.6008,  13.7920, -21.7230,  12.6369,  -3.7268,
        -14.8119, -22.0637,  12.9468, -22.1610,  -6.1827, -14.8119,  -3.2838, -15.4540, -11.6950,  -2.9926,  -3.0110, -21.5664, -13.8268,
          7.3426, -21.8418,   5.0744,   5.2582,  13.3415, -21.6289, -13.9898, -21.8112,  -7.3316,   5.2296, -13.4453,  12.7891, -22.1235,
        -14.9625,  -3.4339,   6.3089, -21.9839,   3.1968,   7.2400,   2.8558,  -3.1187,   3.7965,   5.4667, -15.1101, -15.0597, -22.9391,
        -21.7230,  -3.0346, -13.5206, -21.7011,  13.4425,  -7.2690, -21.8335, -12.0582,  13.0489,   6.7993,   5.2160,   5.0794, -12.6957,
        -12.1838,  -3.0873, -21.6070,   7.0744, -21.7170, -22.1001,   6.8159, -11.6002, -21.6310])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we are multiplying elements together then summing accross rows. This is identical to the linear algebra operation of a <em>matrix-vector product</em>. This operation has been implemented in Pytorch and uses the '@' symbol, so we can write the above in a simpler way as:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">val_indep</span><span class="nd">@coeffs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([ 12.3288, -14.8119, -15.4540, -13.1513, -13.3511, -13.6468,   3.6248,   5.3429, -22.0878,   3.1233, -21.8742, -15.6421, -21.5504,
          3.9393, -21.9190, -12.0010, -12.3775,   5.3550, -13.5880,  -3.1015, -21.7237, -12.2081,  12.9767,   4.7427, -21.6525, -14.9135,
         -2.7433, -12.3210, -21.5886,   3.9387,   5.3890,  -3.6196, -21.6296, -21.8454,  12.2159,  -3.2275, -12.0289,  13.4560, -21.7230,
         -3.1366, -13.2462, -21.7230, -13.6831,  13.3092, -21.6477,  -3.5868, -21.6854, -21.8316, -14.8158,  -2.9386,  -5.3103, -22.2384,
        -22.1097, -21.7466, -13.3780, -13.4909, -14.8119, -22.0690, -21.6666, -21.7818,  -5.4439, -21.7407, -12.6551, -21.6671,   4.9238,
        -11.5777, -13.3323, -21.9638, -15.3030,   5.0243, -21.7614,   3.1820, -13.4721, -21.7170, -11.6066, -21.5737, -21.7230, -11.9652,
        -13.2382, -13.7599, -13.2170,  13.1347, -21.7049, -21.7268,   4.9207,  -7.3198,  -5.3081,   7.1065,  11.4948, -13.3135, -21.8723,
        -21.7230,  13.3603, -15.5670,   3.4105,  -7.2857, -13.7197,   3.6909,   3.9763, -14.7227, -21.8268,   3.9387, -21.8743, -21.8367,
        -11.8518, -13.6712, -21.8299,   4.9440,  -5.4471, -21.9666,   5.1333,  -3.2187, -11.6008,  13.7920, -21.7230,  12.6369,  -3.7268,
        -14.8119, -22.0637,  12.9468, -22.1610,  -6.1827, -14.8119,  -3.2838, -15.4540, -11.6950,  -2.9926,  -3.0110, -21.5664, -13.8268,
          7.3426, -21.8418,   5.0744,   5.2582,  13.3415, -21.6289, -13.9898, -21.8112,  -7.3316,   5.2296, -13.4453,  12.7891, -22.1235,
        -14.9625,  -3.4339,   6.3089, -21.9839,   3.1968,   7.2400,   2.8558,  -3.1187,   3.7965,   5.4667, -15.1101, -15.0597, -22.9391,
        -21.7230,  -3.0346, -13.5206, -21.7011,  13.4425,  -7.2690, -21.8335, -12.0582,  13.0489,   6.7993,   5.2160,   5.0794, -12.6957,
        -12.1838,  -3.0873, -21.6070,   7.0744, -21.7170, -22.1001,   6.8159, -11.6002, -21.6310])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Not only is this simpler, but matrix-vector products in PyTorch have been highly optimised to make them much faster. So not only is the code for this more compact, this actually runs much faster than using the normal multiplication and sum.</p>
<p>Let's update our predictions function with this.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">calc_preds</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">indeps</span><span class="p">):</span> 
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">indeps</span><span class="nd">@coeffs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Creating-a-Neural-Network-Model">
<a class="anchor" href="#Creating-a-Neural-Network-Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating a Neural Network Model<a class="anchor-link" href="#Creating-a-Neural-Network-Model"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will now transition to creating a simple neural network model, which will build on what we have used to make our linear model.</p>
<p>For this type of model we will need to perform <em>matrix-matrix products</em> and to do this we will need to turn the coefficients into a column vector i.e. a matrix with a single column which we can do by passing a second argument 1 to torch.rand(), indicating that we want our coefficients to have one column.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">init_coeffs</span><span class="p">():</span> 
    <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_coeff</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll also need to turn our dependent variable into a column vector, which we can do by indexing the column dimension with the special value None, which tells PyTorch to add a new dimension in this position:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">trn_dep</span> <span class="o">=</span> <span class="n">trn_dep</span><span class="p">[:,</span><span class="kc">None</span><span class="p">]</span>
<span class="n">val_dep</span> <span class="o">=</span> <span class="n">val_dep</span><span class="p">[:,</span><span class="kc">None</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can now train our model as before and confirm we get identical outputs...</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">coeffs</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.512; 0.323; 0.290; 0.205; 0.200; 0.198; 0.197; 0.197; 0.196; 0.196; 0.196; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; </pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>...and identical accuracy:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">acc</span><span class="p">(</span><span class="n">coeffs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(0.8258)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So what is a Neural Network? In <a href="https://en.wikipedia.org/wiki/Artificial_neural_network">simple terms</a></p>
<blockquote>
<p><em>Artificial neural networks (ANNs), usually simply called neural networks (NNs) or neural nets are computing systems inspired by the biological neural networks that constitute animal brains. An ANN is based on a collection of connected units or nodes called artificial neurons, which loosely model the neurons in a biological brain</em></p>
</blockquote>
<p><strong>One key difference between Neural Networks (NN) and Linear Regression (LR), is that while LR has model parameters/coefficients one for each input variable, NN's have many model parameters, many of which do not correspond to specific input variables which are often called 'hidden layers'</strong>.</p>
<p><img src="https://github.com/pranath/blog/raw/master/images/simple_nn.png" alt="" title="A Simple Neural Network">
You can read more about <a href="https://www.investopedia.com/terms/n/neuralnetwork.asp#:~:text=A%20neural%20network%20is%20a,organic%20or%20artificial%20in%20nature.">Neural Networks here</a>.</p>
<p>To create a Neural Network we'll need to create coefficients for each of our layers. Our first set of coefficients will take our n_coeff inputs, and create n_hidden outputs for our hidden layers. We can choose whatever n_hidden we like -- a higher number gives our network more flexibility, but makes it slower and harder to train. So we need a matrix of size n_coeff by n_hidden. We'll divide these coefficients by n_hidden so that when we sum them up in the next layer we'll end up with similar magnitude numbers to what we started with.</p>
<p>Then our second layer will need to take the n_hidden inputs and create a single output, so that means we need a n_hidden by 1 matrix there. The second layer will also need a constant term added.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">init_coeffs</span><span class="p">(</span><span class="n">n_hidden</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">layer1</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_coeff</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">)</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span><span class="o">/</span><span class="n">n_hidden</span>
    <span class="n">layer2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">-</span><span class="mf">0.3</span>
    <span class="n">const</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">layer1</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(),</span><span class="n">layer2</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(),</span><span class="n">const</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we have our coefficients, we can create our neural net. The key steps are the two matrix products, indeps@l1 and res@l2 (where res is the output of the first layer). The first layer output is passed to F.relu (that's our non-linearity), and the second is passed to torch.sigmoid as before.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">calc_preds</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">indeps</span><span class="p">):</span>
    <span class="n">l1</span><span class="p">,</span><span class="n">l2</span><span class="p">,</span><span class="n">const</span> <span class="o">=</span> <span class="n">coeffs</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">indeps</span><span class="nd">@l1</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="nd">@l2</span> <span class="o">+</span> <span class="n">const</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, now that we have more than one set of coefficients, we need to add a loop to update each one:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">update_coeffs</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">coeffs</span><span class="p">:</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">sub_</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">grad</span> <span class="o">*</span> <span class="n">lr</span><span class="p">)</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's train our model.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">coeffs</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1.4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.543; 0.532; 0.520; 0.505; 0.487; 0.466; 0.439; 0.407; 0.373; 0.343; 0.319; 0.301; 0.286; 0.274; 0.264; 0.256; 0.250; 0.245; 0.240; 0.237; 0.234; 0.231; 0.229; 0.227; 0.226; 0.224; 0.223; 0.222; 0.221; 0.220; </pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">coeffs</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.543; 0.400; 0.260; 0.390; 0.221; 0.211; 0.197; 0.195; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; </pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">acc</span><span class="p">(</span><span class="n">coeffs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(0.8258)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this case our neural net isn't showing better results than the linear model. That's not surprising; this dataset is very small and very simple, and isn't the kind of thing we'd expect to see neural networks excel at. Furthermore, our validation set is too small to reliably see much accuracy difference. But the key thing is that we now know exactly what a real neural net looks like, and can see how it relates to a linear regression model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Creating-a-Deep-Learning-Model">
<a class="anchor" href="#Creating-a-Deep-Learning-Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating a Deep Learning Model<a class="anchor-link" href="#Creating-a-Deep-Learning-Model"> </a>
</h2>
<p>The neural net in the previous section only uses one hidden layer, so it doesn't count as "deep" learning. But we can use the exact same technique to make our neural net deep, by adding more 'hidden layers'.</p>
<p>First, we'll need to create additional coefficients for each layer:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">init_coeffs</span><span class="p">():</span>
    <span class="n">hiddens</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>  <span class="c1"># &lt;-- set this to the size of each hidden layer you want</span>
    <span class="n">sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_coeff</span><span class="p">]</span> <span class="o">+</span> <span class="n">hiddens</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">sizes</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span><span class="o">-</span><span class="mf">0.3</span><span class="p">)</span><span class="o">/</span><span class="n">sizes</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">4</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
    <span class="n">consts</span> <span class="o">=</span> <span class="p">[(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span><span class="o">*</span><span class="mf">0.1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">layers</span><span class="o">+</span><span class="n">consts</span><span class="p">:</span> <span class="n">l</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">layers</span><span class="p">,</span><span class="n">consts</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You'll notice here that there's a lot of messy constants to get the random numbers in just the right ranges. When we train the model in a moment, you'll see that the tiniest changes to these initialisations can cause our model to fail to train at all.</p>
<p><strong>This is a key reason that deep learning failed to make much progress in the early days - it's very finicky to get a good starting point for our coefficients. Nowadays, we have better ways to deal with that.</strong></p>
<p>Our deep learning calc_preds looks much the same as before, but now we loop through each layer, instead of listing them separately:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">calc_preds</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">indeps</span><span class="p">):</span>
    <span class="n">layers</span><span class="p">,</span><span class="n">consts</span> <span class="o">=</span> <span class="n">coeffs</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">indeps</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">layers</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="nd">@l</span> <span class="o">+</span> <span class="n">consts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">i</span><span class="o">!=</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="n">res</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We also need a minor update to update_coeffs since we've got layers and consts separated now:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">update_coeffs</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
    <span class="n">layers</span><span class="p">,</span><span class="n">consts</span> <span class="o">=</span> <span class="n">coeffs</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">layers</span><span class="o">+</span><span class="n">consts</span><span class="p">:</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">sub_</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">grad</span> <span class="o">*</span> <span class="n">lr</span><span class="p">)</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's train our model...</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">coeffs</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.521; 0.483; 0.427; 0.379; 0.379; 0.379; 0.379; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.377; 0.376; 0.371; 0.333; 0.239; 0.224; 0.208; 0.204; 0.203; 0.203; 0.207; 0.197; 0.196; 0.195; </pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">acc</span><span class="p">(</span><span class="n">coeffs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(0.8258)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The "real" deep learning models that are used in research and industry look very similar to this, and in fact if you look inside the source code of any deep learning model you'll recognise the basic steps are the same.</p>
<p>The biggest differences in practical models to what we have above are:</p>
<ul>
<li>How initialisation and normalisation is done to ensure the model trains correctly every time</li>
<li>Regularization (to avoid over-fitting)</li>
<li>Modifying the neural net itself to take advantage of knowledge of the problem domain</li>
<li>Doing gradient descent steps on smaller batches, rather than the whole dataset</li>
</ul>

</div>
</div>
</div>
</div>



  </div>
  
  <a class="u-url" href="/fastai/fastai-2022/deep-learning/mathematics/2022/12/17/machine-learning-to-deep-learning-from-scratch.html" hidden></a>
</article><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="pranath/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">
    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"></ul>
</div>

  </div>

</footer>
<script type="text/javascript" src="/js/lightbox.js"></script>
<link rel="stylesheet" href="/css/lightbox.css">
</body>

</html>
