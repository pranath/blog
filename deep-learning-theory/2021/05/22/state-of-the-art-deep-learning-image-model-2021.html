<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>State-of-the-art Deep Learning image model techniques in 2021 | livingdatalab</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="State-of-the-art Deep Learning image model techniques in 2021" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In this article we are going to look at some of the most advanced techniques available in 2021 for training deep learning vision models." />
<meta property="og:description" content="In this article we are going to look at some of the most advanced techniques available in 2021 for training deep learning vision models." />
<link rel="canonical" href="https://www.livingdatalab.com/deep-learning-theory/2021/05/22/state-of-the-art-deep-learning-image-model-2021.html" />
<meta property="og:url" content="https://www.livingdatalab.com/deep-learning-theory/2021/05/22/state-of-the-art-deep-learning-image-model-2021.html" />
<meta property="og:site_name" content="livingdatalab" />
<meta property="og:image" content="https://www.livingdatalab.com/images/deep1.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-05-22T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://www.livingdatalab.com/deep-learning-theory/2021/05/22/state-of-the-art-deep-learning-image-model-2021.html","@type":"BlogPosting","headline":"State-of-the-art Deep Learning image model techniques in 2021","dateModified":"2021-05-22T00:00:00-05:00","datePublished":"2021-05-22T00:00:00-05:00","image":"https://www.livingdatalab.com/images/deep1.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.livingdatalab.com/deep-learning-theory/2021/05/22/state-of-the-art-deep-learning-image-model-2021.html"},"description":"In this article we are going to look at some of the most advanced techniques available in 2021 for training deep learning vision models.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://www.livingdatalab.com/feed.xml" title="livingdatalab" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-91568149-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">livingdatalab</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Livingdatalab</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">State-of-the-art Deep Learning image model techniques in 2021</h1><p class="page-description">In this article we are going to look at some of the most advanced techniques available in 2021 for training deep learning vision models.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-05-22T00:00:00-05:00" itemprop="datePublished">
        May 22, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      4 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#deep-learning-theory">deep-learning-theory</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#introduction">Introduction</a></li>
<li class="toc-entry toc-h2"><a href="#library-and-dataset">Library and Dataset</a></li>
<li class="toc-entry toc-h2"><a href="#normalisation">Normalisation</a></li>
<li class="toc-entry toc-h2"><a href="#progressive-resizing">Progressive resizing</a></li>
<li class="toc-entry toc-h2"><a href="#test-time-augmentation">Test time augmentation</a></li>
<li class="toc-entry toc-h2"><a href="#mixup">Mixup</a></li>
<li class="toc-entry toc-h2"><a href="#label-smoothing">Label smoothing</a></li>
<li class="toc-entry toc-h2"><a href="#conclusion">Conclusion</a></li>
</ul><h2 id="introduction">
<a class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h2>

<p>In this article we are going to look at some of the most advanced techniques available in 2021 for training deep learning vision models. These go beyond the basics of mini-batch gradient descent, learning rates, pre-sizing, transfer learning, discriminative learning rates, and mixed-precision training.</p>

<h2 id="library-and-dataset">
<a class="anchor" href="#library-and-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Library and Dataset</h2>

<p>I will be using the fastai deep learning library for code examples, as well as the fastai curated <em>Imagenette</em> dataset which is a specially curated subset of the well known ImageNet dataet of 1.3 million images from 1,000 categories. The Imagenette dataset consists of a much smaller set of images and just 10 categories of images.</p>

<p>We will define a baseline model here using the dataset to then compare the effect of each advanced techniques.</p>

<p><img src="/images/sota-vision/sota-vision1.png" alt="" title=" "></p>

<h2 id="normalisation">
<a class="anchor" href="#normalisation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Normalisation</h2>

<p>When training a model, its helpful to ensure the image data is normalised. This ensures that different images end up with data that is in the same range of values, which helps the model better focus more on the content on the images. So here by normalised we mean we want the image data values to have a mean of 0 and a standard deviation of 1.</p>

<p>The fastai library will automatically normalise images per batch, and this is suitable for models that we might train from scratch. When using transfer learning this default approach is not a good idea, because a pre-trained model has been trained on image data with a particular mean and standard deviation. So to use a pre-trained model with new images, we need to ensure these new images are normalised to the same mean and standard deviation that the original model data was trained with.</p>

<p>We can do this my specifying particular normalisation stats in fastai, which already knows the normalisation stats for many common datasets, including of course fastai’s own Imagenette dataset which makes it much easier.</p>

<p>We can also define a function <strong>get_dls()</strong> which will make it easier to define different types of data loader i.e. with different batch or image sizes.</p>

<p><img src="/images/sota-vision/sota-vision2.png" alt="" title=" "></p>

<p>After applying our normalisation, we can see the mean and standard deviation are approximatly 0 and 1 respectively on a test batch of images.</p>

<p>Lets now try this normalised data and train our model.</p>

<p><img src="/images/sota-vision/sota-vision3.png" alt="" title=" "></p>

<p>While normalisation here hasn’t made a huge improvement over our baseline model, normalisation does make a bigger difference especially with bigger models and more data.</p>

<h2 id="progressive-resizing">
<a class="anchor" href="#progressive-resizing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Progressive resizing</h2>

<p>Progressive re-sizing is another technique pioneered by fastai. Essentially this involves training models on smaller versions of the images first, before continuing training on bigger images. This has 2 major benefits:</p>

<ul>
  <li>Model training time is much faster</li>
  <li>Model accuracy ends up better than if we trained the model only on bigger images</li>
</ul>

<p>How can this be the case? lets remember that with convolutional deep learning models, early layers focus on recognising primitive features like lines and edges, and later layers more composite features such as eyes or fur. So if we change the image size during training, our earlier model will still have learnt many useful things applicable to bigger and higher resolution images.</p>

<p>In a way, this is a bit like training a model in one area then re-using that model on a similar area - which might sound familiar? As it should since this is very much what transfer learning is about as well, which works very well. So we should perhaps not be so surprised that this could work well.</p>

<p>Another benefit of using lower resolution/smaller versions of the images first is that this is another kind of data augmentation - which should also help our models generalise better.</p>

<p>So lets use our <em>get_dls()</em> function that we defined earlier to define a data loader for our smaller lower resolution images and train the model for a few epochs.</p>

<p><img src="/images/sota-vision/sota-vision4.png" alt="" title=" "></p>

<p>We will the define a new data loader with bigger images, and continue to train our model with these.</p>

<p><img src="/images/sota-vision/sota-vision5.png" alt="" title=" "></p>

<p>So we can see we are already getting much better results than our baseline with just a few epochs, and much more quickly. It’s worth considering for the desire task, for transfer learning can in some cases harm performance. This might happen for example if the pre-trained model is trained on images already quite similar to the new ones you want to recognise - as in this case the model parameters are likely already quite close to what is needed, and progressive resizing could move the parameters further away from this and good results. If the use case is for the pre-rained model is very different to what it was originally trained on i.e. very different sizes, shapes, styles etc - then progressive resizing here might actually help.</p>

<p>In either case, trying things experimentally would probably be the best way to determine which was the better approach.</p>

<h2 id="test-time-augmentation">
<a class="anchor" href="#test-time-augmentation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Test time augmentation</h2>

<h2 id="mixup">
<a class="anchor" href="#mixup" aria-hidden="true"><span class="octicon octicon-link"></span></a>Mixup</h2>

<h2 id="label-smoothing">
<a class="anchor" href="#label-smoothing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Label smoothing</h2>

<h2 id="conclusion">
<a class="anchor" href="#conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion</h2>

  </div>
  
  <a class="u-url" href="/deep-learning-theory/2021/05/22/state-of-the-art-deep-learning-image-model-2021.html" hidden></a>
</article><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="pranath/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">
    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/pranath" title="pranath"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/pranath-fernando" title="pranath-fernando"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/livingdatalab" title="livingdatalab"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
<script type="text/javascript" src="/js/lightbox.js"></script>
<link rel="stylesheet" href="/css/lightbox.css">
</body>

</html>
