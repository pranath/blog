<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Topic Modelling using Singular Value Decomposition (SVD) | livingdatalab</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Topic Modelling using Singular Value Decomposition (SVD)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Singular Value Decomposition (SVD) is a method from Linear Algebra widley used accross science and engineering. In this article we will introduce the concept and show how it can be used for Topic Modelling in Natural Language Processing (NLP)." />
<meta property="og:description" content="Singular Value Decomposition (SVD) is a method from Linear Algebra widley used accross science and engineering. In this article we will introduce the concept and show how it can be used for Topic Modelling in Natural Language Processing (NLP)." />
<link rel="canonical" href="https://www.livingdatalab.com/mathematics/linear-algebra/natural-language-processing/2021/12/27/topic-modelling-svd.html" />
<meta property="og:url" content="https://www.livingdatalab.com/mathematics/linear-algebra/natural-language-processing/2021/12/27/topic-modelling-svd.html" />
<meta property="og:site_name" content="livingdatalab" />
<meta property="og:image" content="https://www.livingdatalab.com/images/svd.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-12-27T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://www.livingdatalab.com/mathematics/linear-algebra/natural-language-processing/2021/12/27/topic-modelling-svd.html","@type":"BlogPosting","headline":"Topic Modelling using Singular Value Decomposition (SVD)","dateModified":"2021-12-27T00:00:00-06:00","datePublished":"2021-12-27T00:00:00-06:00","image":"https://www.livingdatalab.com/images/svd.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.livingdatalab.com/mathematics/linear-algebra/natural-language-processing/2021/12/27/topic-modelling-svd.html"},"description":"Singular Value Decomposition (SVD) is a method from Linear Algebra widley used accross science and engineering. In this article we will introduce the concept and show how it can be used for Topic Modelling in Natural Language Processing (NLP).","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://www.livingdatalab.com/feed.xml" title="livingdatalab" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-91568149-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">livingdatalab</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Livingdatalab</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Topic Modelling using Singular Value Decomposition (SVD)</h1><p class="page-description">Singular Value Decomposition (SVD) is a method from Linear Algebra widley used accross science and engineering. In this article we will introduce the concept and show how it can be used for Topic Modelling in Natural Language Processing (NLP).</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-12-27T00:00:00-06:00" itemprop="datePublished">
        Dec 27, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      11 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#mathematics">mathematics</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#linear-algebra">linear-algebra</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#natural-language-processing">natural-language-processing</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          
          
          
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Introduction">Introduction </a></li>
<li class="toc-entry toc-h2"><a href="#Dataset">Dataset </a></li>
<li class="toc-entry toc-h2"><a href="#Singular-Value-Decomposition-(SVD)">Singular Value Decomposition (SVD) </a></li>
<li class="toc-entry toc-h2"><a href="#Truncated-SVD">Truncated SVD </a></li>
<li class="toc-entry toc-h2"><a href="#Conclusion">Conclusion </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-12-27-topic-modelling-svd.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction">
<a class="anchor" href="#Introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction<a class="anchor-link" href="#Introduction"> </a>
</h2>
<p><strong>Singular Value Decomposition (SVD)</strong> is a method from Linear Algebra that is used in a wide range of applications in science and engineering. It can be used for tasks such as dimensionality reduction, image compression, and even <a href="https://www.math3ma.com/blog/understanding-entanglement-with-svd">understanding entanglement in quantum theory</a>.</p>
<p><strong>Topic modeling</strong> is an unsupervised machine learning technique used in Natural Language Processing (NLP) that’s capable of scanning a set of texts, detecting word and phrase patterns within them, and automatically clustering word groups and similar expressions that best characterize a set of documents.</p>
<p>In this article we will will use SVD to perform topic modelling.</p>
<p>This article is based in large part on the material from the <a href="https://github.com/fastai/numerical-linear-algebra/blob/master/README.md">fastai linear algebra course</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Dataset">
<a class="anchor" href="#Dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dataset<a class="anchor-link" href="#Dataset"> </a>
</h2>
<p>We will use the <a href="https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups">20 Newsgroups</a> dataset which consists of 20,000 messages taken from 20 different newsgroups from the Usenet bulletin board service, which pre-dates the world-wide-web and websites. We will look at a subset of 4 of these newsgroup categories:</p>
<ul>
<li>rec.motorcycles</li>
<li>talk.politics.mideast</li>
<li>sci.med</li>
<li>sci.crypt</li>
</ul>
<p>We will now get this data.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'rec.motorcycles'</span><span class="p">,</span> <span class="s1">'talk.politics.mideast'</span><span class="p">,</span> <span class="s1">'sci.med'</span><span class="p">,</span> <span class="s1">'sci.crypt'</span><span class="p">]</span>
<span class="n">remove</span> <span class="o">=</span> <span class="p">(</span><span class="s1">'headers'</span><span class="p">,</span> <span class="s1">'footers'</span><span class="p">,</span> <span class="s1">'quotes'</span><span class="p">)</span>
<span class="n">newsgroups_train</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">'train'</span><span class="p">,</span> <span class="n">categories</span><span class="o">=</span><span class="n">categories</span><span class="p">,</span> <span class="n">remove</span><span class="o">=</span><span class="n">remove</span><span class="p">)</span>
<span class="n">newsgroups_test</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">'test'</span><span class="p">,</span> <span class="n">categories</span><span class="o">=</span><span class="n">categories</span><span class="p">,</span> <span class="n">remove</span><span class="o">=</span><span class="n">remove</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's check how many posts this gives us in total</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">filenames</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">newsgroups_train</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((2351,), (2351,))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's print the first few lines of 3 of the posts to see what the text looks like</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)[:</span><span class="mi">3</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
I am not an expert in the cryptography science, but some basic things
seem evident to me, things which this Clinton Clipper do not address.
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)[:</span><span class="mi">3</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Does the Bates method work?  I first heard about it in this newsgroup 
several years ago, and I have just got hold of a book, "How to improve your
sight - simple daily drills in relaxation", by Margaret D. Corbett, 
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)[:</span><span class="mi">3</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Suggest McQuires #1 plastic polish.  It will help somewhat but nothing 
will remove deep scratches without making it worse than it already is.
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can also get the newsgroup category for each from the 'target_names' attribute</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">target_names</span><span class="p">)[</span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">target</span><span class="p">[:</span><span class="mi">3</span><span class="p">]]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array(['sci.crypt', 'sci.med', 'sci.med'], dtype='&lt;U21')</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To use this text dataset for topic modelling we will need to convert this into a <strong>document-term</strong> matrix. This is a matrix where the rows will correspond to to each of the newsgroup posts (a 'document' conceptually) and the columns will be for each of the words that exists in all posts (a 'term' conceptually). The values of the matrix will be the count of the number of words that exists for a particular post for each post/word combination in the matrix.</p>
<p><img src="https://github.com/pranath/blog/raw/master/images/document-term-matrix.png" alt="" title="An example Document-Term matrix"></p>
<p>This method of converting text into a count of the words in the text matrix, without regard for anything else (such as order, context etc) is called a <strong>bag of words</strong> model. We can create this matrix using a <em>CountVectoriser()</em> function.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="s1">'english'</span><span class="p">)</span>
<span class="n">vectors</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">todense</span><span class="p">()</span> <span class="c1"># (documents, vocab)</span>
<span class="n">vectors</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2351, 32291)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see this matrix has the same number of rows as we have posts (2351) and we must have 32,291 unique words accross all posts which is the number of columns we have.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">data</span><span class="p">),</span> <span class="n">vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>2351 (2351, 32291)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If we print the matrix, its just an array of counts for each of the words in each post</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">vectors</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>matrix([[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 2, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This matrix does not actually contain the names of the words, so it will be helpful for us to extract these as well to create a vocabulary of terms used in the matrix. We can extract these using <em>get_feature_names()</em></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">vocab</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
<span class="n">vocab</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(32291,)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">vocab</span><span class="p">[:</span><span class="mi">32000</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array(['00', '000', '0000', ..., 'yarn', 'yarvin', 'yashir'], dtype='&lt;U79')</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>While we have the newsgroup categories here, we will not actually use them for our topic modelling exercise, where we want to create topics independantly based on the posts alone, but we would hope these will correspond to the newsgroup categories in some way, indeed this would be a good check that the topic modelling is working.</p>
<p>Now we have our Document-Term matrix and the vocabulary, we are now ready to use Singular Value Decompostion.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Singular-Value-Decomposition-(SVD)">
<a class="anchor" href="#Singular-Value-Decomposition-(SVD)" aria-hidden="true"><span class="octicon octicon-link"></span></a>Singular Value Decomposition (SVD)<a class="anchor-link" href="#Singular-Value-Decomposition-(SVD)"> </a>
</h2>
<p>SVD is a method of matrix decomposition, so for a given matrix A we can convert it into 3 other matrices: U, $\sum_{}$, and $V^{T}$</p>
<p><img src="https://github.com/pranath/blog/raw/master/images/svd.png" alt="" title="Singular Value Decompositon"></p>
<p>R is a value we choose in advance, in the case of our intention here R will repesent the number of topics we want to create for our topic model of the newsgroup posts.</p>
<p>Each of these matricies represents the following</p>
<ul>
<li>U: <strong>Left singular vectors</strong> this has the same number of rows as our original matrix A (m rows/posts) and a column for each of our chosen number of topics (r columns). This matrix has <em>orthogonal (or orthonormal) columns</em> i.e. vectors along the r topics column axis.</li>
<li>$\sum_{}$: <strong>Singular values</strong> has r rows by r columns, in our case this means topics by topics. This represents the ranked relative importance of each topic so the most important topic is topic 1 which is in row 1, column 1 - and the value at this index will be a measure of the importance, and so on for topic 2 etc. This is a matrix of diagonal singular values (all other values off the diagonal are zero).</li>
<li>$V^{T}$: <strong>Right singular vectors</strong> this has the same number of columns as our original matrix A (n columns) and a row for each of our chosen number of topics (r rows)</li>
</ul>
<p>If we were to choose a R value equal to N this would be an <strong>exact decompostion</strong> of the matrix A, which would mean if we were to multiply U, $\sum_{}$, and $V^{T}$ we would get back exactly the same matrix A.</p>
<p>However there are many reasons why in practice we may not want to do a full decompostion, including in the case of large matricies this can be extermely time consuming, and often we may not require all potential topics, just the most important. So in practice we are likely to choose a value for R that is far smaller than N.</p>
<p><strong>Latent Semantic Analysis (LSA) or Latent Semantic Index (LSI)</strong> is a common name given to applying SVD to topic modelling in NLP in this way i.e. using a Document-Term matrix.</p>
<p>Another way to think about SVD more generally is that whatever is represented by a matrix A by columns M and N, is mapped into a 'latent space' defined by the R dimension. Futhermore, this mapping is done in such a way that co-occuring values of N are projected into the same R dimensions with higher values, and conversley non-couccuring values on N are projected into different R dimensions.</p>
<p>In other words, the latent space R dimensions allow us to show which M are similar or different based on their values of N.</p>
<p>So we can peform full SVD on our Document-Term matrix using the scipy <em>linalg</em> module.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="o">%</span><span class="n">time</span> <span class="n">U</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">Vh</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 1min 55s, sys: 5.34 s, total: 2min
Wall time: 1min 2s
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">U</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Vh</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(2351, 2351) (2351,) (2351, 32291)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This has performed a full SVD, and took around 2 mins.</p>
<p>We can test that this is a decomposition by multipling these matrices and checking if they are close to equal to the original matrix using the <em>allclose()</em> function from numpy.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Confirm that U, s, Vh is a decomposition of the var Vectors</span>
<span class="c1"># Multiply matrices</span>
<span class="n">reconstructed_vectors</span> <span class="o">=</span> <span class="n">U</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">@</span> <span class="n">Vh</span>
<span class="c1"># Calculate the Frobenius norm between the original matrix A and this reconstructed one - which is a measure of the distance/differences between these matrices</span>
<span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">reconstructed_vectors</span> <span class="o">-</span> <span class="n">vectors</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>4.063801905115974e-12</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Check if two matrices are approximately equal within a small difference</span>
<span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">reconstructed_vectors</span><span class="p">,</span> <span class="n">vectors</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>True</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can also check that U and Vh are orthonormal matrices. <a href="https://en.wikipedia.org/wiki/Orthogonal_matrix">If we multiply these by their transpose this should be close to equal to the identity matrix for each of these (by definition).</a>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Confirm that U, Vh are orthonormal</span>
<span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">U</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">U</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">U</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">Vh</span> <span class="o">@</span> <span class="n">Vh</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">Vh</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>True</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If we look at the singular values matrix, we can get an idea of the relative importance of each of the topics (topics on x axis)</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Topic number'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Importance'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Text(0, 0.5, 'Importance')</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's have a look at the topics discovered by SVD, we will do this by looking at the top 8 words that score most highly for each topic. This will be orderded by most important topic first.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">num_top_words</span><span class="o">=</span><span class="mi">8</span>

<span class="k">def</span> <span class="nf">show_topics</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="n">top_words</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">t</span><span class="p">)[:</span><span class="o">-</span><span class="n">num_top_words</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
    <span class="n">topic_words</span> <span class="o">=</span> <span class="p">([</span><span class="n">top_words</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">a</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">[</span><span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">topic_words</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Top 10 topics, described by top words in each topic'</span><span class="p">)</span>
<span class="n">show_topics</span><span class="p">(</span><span class="n">Vh</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Top 10 topics, described by top words in each topic
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>['melittin wimp disgruntled rebelling toxin sorta bikeless litte',
 'db mov bh si bl di maxbyte cx',
 'said didn people know don went apartment came',
 'health 1993 hiv medical use 10 number 20',
 'edu com anonymous health posting anon service cs',
 'key privacy eff pub encryption use law health',
 'internet email privacy anonymous anonymity health eff hiv',
 'anonymous posting anonymity use anon key users postings',
 'com edu encryption privacy government said chip technology',
 'version machines contact type pc comments ftp keyboard']</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So if you recall our original news group categories were:</p>
<ul>
<li>rec.motorcycles</li>
<li>talk.politics.mideast</li>
<li>sci.med</li>
<li>sci.crypt</li>
</ul>
<p>We can see that the topics discovered correspond fairly well to these, bar a few anomalies.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Truncated-SVD">
<a class="anchor" href="#Truncated-SVD" aria-hidden="true"><span class="octicon octicon-link"></span></a>Truncated SVD<a class="anchor-link" href="#Truncated-SVD"> </a>
</h2>
<p>So we saw from our attempt at full SVD was quite slow to calculate (approx 2 mins) we can imagine this is likely to get far worse with bigger matrices. We also know that perhaps we don't need to calculate a full set of topics, especially given for most practical applications we are most likely interested in using the strongest topics that distinguish posts, rather than topics that are not very useful. The approaches to calculate full SVD use particular algorithms to create the decomposition, and <a href="https://arxiv.org/abs/0909.4061">Halko et al</a> highlighted some of the key disadvantages of this approach:</p>
<ul>
<li>Matrices are "stupendously big"</li>
<li>Data are often missing or inaccurate. Why spend extra computational resources when imprecision of input limits precision of the output?</li>
<li>Data transfer now plays a major role in time of algorithms. Techniques the require fewer passes over the data may be substantially faster, even if they require more flops (flops = floating point operations).</li>
<li>Important to take advantage of GPUs.</li>
</ul>
<p>In the same paper, Halko et al argued for the advantages of using randomised approaches which include:</p>
<ul>
<li>They are inherently stable</li>
<li>Performance guarantees do not depend on subtle spectral properties</li>
<li>Needed matrix-vector products can be done in parallel i.e. on a GPU</li>
</ul>
<p>So <strong>Truncated SVD</strong> using a randomised approach, allows us to calculate just the largest singular values and the corresponding matrices, which should be much quicker to calculate.</p>
<p>We can use sklearn's <em>decomposition</em> module to calculated randomised SVD, we will specify the top 10 topics only.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="o">%</span><span class="n">time</span> <span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">decomposition</span><span class="o">.</span><span class="n">randomized_svd</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 18.7 s, sys: 2.09 s, total: 20.8 s
Wall time: 15.2 s
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets see the top 10 topics its discovered.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">show_topics</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>['db mov bh si cs byte al bl',
 'people said know don didn anonymous privacy internet',
 'privacy internet anonymous information pub email eff use',
 'health 1993 hiv medical use 10 number 20',
 'turkish jews turkey key privacy government armenian eff',
 'turkish edu jews com turkey anonymous jewish nazis',
 'key edu encryption des com ripem chip keys',
 'com edu pub eff ftp electronic org computer',
 'dod rec denizens motorcycle motorcycles doom ftp terrible',
 'version machines contact type pc comments ftp keyboard']</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So this is much faster taking a total of 20 seconds for randomised SVD compared to the full SVD of 2 minutes.</p>
<p><a href="https://research.facebook.com/blog/2014/09/fast-randomized-svd/">Facebook Research implemented a version of Randomised SVD</a> based on the Halko paper.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Conclusion">
<a class="anchor" href="#Conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion<a class="anchor-link" href="#Conclusion"> </a>
</h2>
<p>In this article we introduced Singular Value Decomposition (SVD) and saw how it could be applied to the task of topic modelling in NLP. We also saw how this could be optimised for speed when only concerned with the most important topics, using truncated SVD implemented using a randomised approach.</p>

</div>
</div>
</div>
</div>



  </div>
  
  <a class="u-url" href="/mathematics/linear-algebra/natural-language-processing/2021/12/27/topic-modelling-svd.html" hidden></a>
</article><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="pranath/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">
    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="/feed.xml" target="_blank" title="rss">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://github.com/pranath/" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://twitter.com/livingdatalab" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://www.linkedin.com/in/pranath-fernando/" target="_blank" title="linkedin">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#linkedin"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
<script type="text/javascript" src="/js/lightbox.js"></script>
<link rel="stylesheet" href="/css/lightbox.css">
</body>

</html>
